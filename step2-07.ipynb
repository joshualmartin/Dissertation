{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9af98568-db11-4b00-9546-6cd0c9e4a154",
   "metadata": {},
   "source": [
    "# Step 2.7: Getting Word Error Rates (WER)\n",
    "\n",
    "This code will get the Word Error Rate (WER) for each ASR output. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f27e6b-6798-4684-9d4b-b505d5bbc52f",
   "metadata": {},
   "source": [
    "## Required Packages\n",
    "\n",
    "The following packages are necessary to run this code: re, os, [pandas](https://pypi.org/project/pandas/), [numpy](https://pypi.org/project/numpy/), [wagnerfischerpp](https://gist.github.com/kylebgorman/8034009)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b082f58c-3a5c-4109-91ae-bf6083dbf0da",
   "metadata": {},
   "source": [
    "## Intitial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9910a3-9f2c-450d-b5e8-70c68efaef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f9bcf7-7295-44d6-8ef7-dabff40708fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath for the csv produced in Step 2.6\n",
    "aint_file_path =\"path\"\n",
    "\n",
    "be_file_path = \"path\"\n",
    "\n",
    "done_file_path = \"path\"\n",
    "\n",
    "#reads in the gold standard dataframe    \n",
    "aint_gs_df = pd.read_csv(aint_file_path)\n",
    "\n",
    "be_gs_df = pd.read_csv(be_file_path)\n",
    "\n",
    "done_gs_df = pd.read_csv(done_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b575a508-d9e1-45d9-8664-a098566d539a",
   "metadata": {},
   "source": [
    "## Defining the Word Error Rate Getting Function\n",
    "\n",
    "This function depends on the importation of the wagnerfischerpp python script. To do so, follow these steps:\n",
    "1. Go to https://gist.github.com/kylebgorman/8034009.\n",
    "2. Download the wagnerfischerpp.py script.\n",
    "3. Move the script into the current working directory you are working in with this code.\n",
    "4. For a test, run *from wagnerfishcerpp import \\** to make sure it works.\n",
    "\n",
    "This function takes one argument:\n",
    "1. The original utterance content as a string\n",
    "2. The ASR output content as a string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524fc275-43b8-468a-b4c4-f604bd721a70",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "The *getWER* function is directly adapted from the work of [Kyle Gorman](https://gist.github.com/kylebgorman) (see code [here](https://gist.github.com/kylebgorman/8034009))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54e5c5f-ed40-46f8-9e5c-18e1582fa685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWER(original_utterance, ASR_output):\n",
    "    \n",
    "    \"\"\"\n",
    "    Gets the word error rate from the ASR inference\n",
    "    Depends on wagnerfischerpp. Have the wagnerfischerpp.py file in the\n",
    "    same directory and then run from wagnerfischerpp import * before using this.\n",
    "    original_utterance and ASR_output should be strings.\n",
    "    this function will break them into lists\n",
    "    \"\"\"\n",
    "    \n",
    "    from wagnerfischerpp import WagnerFischer\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    if type(original_utterance) != str or type(ASR_output) != str:\n",
    "        \n",
    "        return np.nan\n",
    "    \n",
    "    else:\n",
    "        original_list = original_utterance.split()\n",
    "        \n",
    "        ASR_list = ASR_output.split()\n",
    "        \n",
    "        getter = WagnerFischer(original_list, ASR_list)\n",
    "        \n",
    "        cost = getter.cost\n",
    "        \n",
    "        wer = cost/len(original_list)\n",
    "        \n",
    "        return wer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc21f853-1ba1-4f40-8a25-51d17bbfe75d",
   "metadata": {},
   "source": [
    "## Executing the Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccd65c1-d80a-4370-b8a0-10a0a1851ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of column names to be appended next to\n",
    "column_names = [\"amazon_transcription_cleaned_WordCount\", \n",
    "                \"deepspeech_transcription_cleaned_WordCount\", \"google_transcription_cleaned_WordCount\", \n",
    "                \"IBMWatson_transcription_cleaned_WordCount\", \"microsoft_transcription_cleaned_WordCount\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63203f6b-2d23-492b-a8c3-6bfd15f0125d",
   "metadata": {},
   "source": [
    "### Feature: Ain't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0fe7a4-fbb7-454c-8320-1853dfa98a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds new columns to the dataframe\n",
    "for column_name in column_names:\n",
    "    \n",
    "    col_index = aint_gs_df.columns.get_loc(column_name)\n",
    "\n",
    "    aint_gs_df.insert(col_index+1, f\"{column_name.split('_W')[0]}_TotalWER\", np.nan)\n",
    "    \n",
    "\n",
    "# gets the WER for each line\n",
    "for file_row in aint_gs_df.itertuples():\n",
    "    \n",
    "    aint_gs_df.loc[file_row.Index, \"amazon_transcription_cleaned_TotalWER\"] = getWER(file_row.Content_cleaned, file_row.amazon_transcription_cleaned)\n",
    "    \n",
    "    aint_gs_df.loc[file_row.Index, \"deepspeech_transcription_cleaned_TotalWER\"] = getWER(file_row.Content_cleaned, file_row.deepspeech_transcription_cleaned)\n",
    "    \n",
    "    aint_gs_df.loc[file_row.Index, \"google_transcription_cleaned_TotalWER\"] = getWER(file_row.Content_cleaned, file_row.google_transcription_cleaned)\n",
    "\n",
    "    aint_gs_df.loc[file_row.Index, \"IBMWatson_transcription_cleaned_TotalWER\"] = getWER(file_row.Content_cleaned, file_row.IBMWatson_transcription_cleaned)\n",
    "    \n",
    "    aint_gs_df.loc[file_row.Index, \"microsoft_transcription_cleaned_TotalWER\"] = getWER(file_row.Content_cleaned, file_row.microsoft_transcription_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2459f839-307e-4e80-a648-1842e9f01eb5",
   "metadata": {},
   "source": [
    "### Feature: Be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faa61f4-9499-4a75-afcd-b44d3509ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds new columns to the dataframe\n",
    "for column_name in column_names:\n",
    "    \n",
    "    col_index = be_gs_df.columns.get_loc(column_name)\n",
    "\n",
    "    be_gs_df.insert(col_index+1, f\"{column_name.split('_W')[0]}_TotalWER\", np.nan)\n",
    "    \n",
    "\n",
    "# gets the WER for each line\n",
    "for file_row in be_gs_df.itertuples():\n",
    "    \n",
    "    be_gs_df.loc[file_row.Index, \"amazon_transcription_cleaned_TotalWER\"] = getWER(file_row.Content_cleaned, file_row.amazon_transcription_cleaned)\n",
    "    \n",
    "    be_gs_df.loc[file_row.Index, \"deepspeech_transcription_cleaned_TotalWER\"] = getWER(file_row.Content_cleaned, file_row.deepspeech_transcription_cleaned)\n",
    "    \n",
    "    be_gs_df.loc[file_row.Index, \"google_transcription_cleaned_TotalWER\"] = getWER(file_row.Content_cleaned, file_row.google_transcription_cleaned)\n",
    "\n",
    "    be_gs_df.loc[file_row.Index, \"IBMWatson_transcription_cleaned_TotalWER\"] = getWER(file_row.Content_cleaned, file_row.IBMWatson_transcription_cleaned)\n",
    "    \n",
    "    be_gs_df.loc[file_row.Index, \"microsoft_transcription_cleaned_TotalWER\"] = getWER(file_row.Content_cleaned, file_row.microsoft_transcription_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1db1093-19ed-4e4b-be56-0aec20f9002c",
   "metadata": {},
   "source": [
    "### Feature: Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb105bf-9f1c-470e-ba6c-9db49b30ec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds new columns to the dataframe\n",
    "for column_name in column_names:\n",
    "    \n",
    "    col_index = done_gs_df.columns.get_loc(column_name)\n",
    "\n",
    "    done_gs_df.insert(col_index+1, f\"{column_name.split('_W')[0]}_TotalWER\", np.nan)\n",
    "    \n",
    "\n",
    "# gets the WER for each line\n",
    "for file_row in done_gs_df.itertuples():\n",
    "    \n",
    "    done_gs_df.loc[file_row.Index, \"amazon_transcription_cleaned_TotalWER\"] = getWER(file_row.Content_cleaned, file_row.amazon_transcription_cleaned)\n",
    "    \n",
    "    done_gs_df.loc[file_row.Index, \"deepspeech_transcription_cleaned_TotalWER\"] = getWER(file_row.Content_cleaned, file_row.deepspeech_transcription_cleaned)\n",
    "    \n",
    "    done_gs_df.loc[file_row.Index, \"google_transcription_cleaned_TotalWER\"] = getWER(file_row.Content_cleaned, file_row.google_transcription_cleaned)\n",
    "\n",
    "    done_gs_df.loc[file_row.Index, \"IBMWatson_transcription_cleaned_TotalWER\"] = getWER(file_row.Content_cleaned, file_row.IBMWatson_transcription_cleaned)\n",
    "    \n",
    "    done_gs_df.loc[file_row.Index, \"microsoft_transcription_cleaned_TotalWER\"] = getWER(file_row.Content_cleaned, file_row.microsoft_transcription_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0c303e-b650-4e9d-bc79-e279751611fe",
   "metadata": {},
   "source": [
    "## Sorting the Dataframes by File and Line\n",
    "\n",
    "This will sort the dataframes first by filename and then by line number. Doing this each step will ensure consistency across the board."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef57205-3bfd-4933-bdbe-5f8e6e75ea9d",
   "metadata": {},
   "source": [
    "### Feature: Ain't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f32913-4e1f-44ea-bd82-f0fdbfd167c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aint_gs_df = aint_gs_df.sort_values(by=['File', 'Line'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a08157-c6a8-4cbb-8978-e6af4b931a7e",
   "metadata": {},
   "source": [
    "### Feature: Be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af12356d-7ffb-4af6-9c58-21e00fae9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "be_gs_df = be_gs_df.sort_values(by=['File', 'Line'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39cd837-4bb3-4129-b4db-583aeb11ea90",
   "metadata": {},
   "source": [
    "### Feature: Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cc53ff-73c4-484b-ad31-2025fba38270",
   "metadata": {},
   "outputs": [],
   "source": [
    "done_gs_df = done_gs_df.sort_values(by=['File', 'Line'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f983788-c9a5-4b73-8a2e-1d18a6ae24b9",
   "metadata": {},
   "source": [
    "## Exporting Dataframes to CSV Files\n",
    "\n",
    "This will export the dataframes to CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ff3dee-e5ab-47f3-a75d-14de88610b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate the output path where the CSVs will be stored\n",
    "csv_output_path = \"path\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44331a54-e11e-4b58-813a-717796e37e73",
   "metadata": {},
   "source": [
    "### Feature: Ain't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247e3561-7148-4ace-aa8f-2e2ca60a93e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aint_gs_df.to_csv(f\"{csv_output_path}aint_variations_totalWER.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf982d6-41cb-46d8-9917-8d4a6a5bdd4d",
   "metadata": {},
   "source": [
    "### Feature: Be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b6042b-fa7e-4017-aac3-7cfca0b8fc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "be_gs_df.to_csv(f\"{csv_output_path}be_totalWER.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101802dd-7fd7-4676-a52b-8b9d76e1c990",
   "metadata": {},
   "source": [
    "### Feature: Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4cab56-e32a-467e-aa8e-12a6640b5ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "done_gs_df.to_csv(f\"{csv_output_path}done_totalWER.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3df4499-4d1b-4953-939e-b1179bebf0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
