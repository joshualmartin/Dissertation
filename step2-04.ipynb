{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9af98568-db11-4b00-9546-6cd0c9e4a154",
   "metadata": {},
   "source": [
    "# Step 2.4: Getting Transcriptions from Automatic Speech Recognition (ASR) Services\n",
    "\n",
    "This code will take the parsed audio files produced in Step 2.1, run them through five ASR services, return the transcriptions, and write them to a pandas dataframe that will be exported to a CSV. Setting up the pipeline for each of these is a bit of a detailed and complex process, so be sure to read and follow the instructions provided in each section carefully.\n",
    "\n",
    "The five ASR services are:\n",
    "\n",
    "1. [Amazon Transcribe](https://aws.amazon.com/transcribe/)\n",
    "2. [DeepSpeech](https://deepspeech.readthedocs.io/en/r0.9/)\n",
    "3. [Google Cloud Speech-to-Text](https://cloud.google.com/speech-to-text)\n",
    "4. [IBM Watson Speech-to-Text](https://www.ibm.com/cloud/watson-speech-to-text)\n",
    "5. [Microsoft Azure Cognitive Services Speech-to-Text](https://azure.microsoft.com/en-us/services/cognitive-services/speech-to-text/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f27e6b-6798-4684-9d4b-b505d5bbc52f",
   "metadata": {},
   "source": [
    "## Required Packages\n",
    "\n",
    "The following packages are necessary to run this code:\n",
    "os, time, urllib, json, wave, [pandas](https://pypi.org/project/pandas/), [numpy](https://pypi.org/project/numpy/), [ibm_watson](https://pypi.org/project/ibm-watson/), [ibm_cloud_sdk_core](https://pypi.org/project/ibm-cloud-sdk-core/), [google-cloud-speech](https://pypi.org/project/google-cloud-speech/), [azure-cognitiveservices-speech](https://pypi.org/project/azure-cognitiveservices-speech/), [boto3](https://pypi.org/project/boto3/), [deepspeech](https://pypi.org/project/deepspeech/) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5221c65d-dbf1-4d96-a712-1fda33232cfd",
   "metadata": {},
   "source": [
    "## Initial Set-Up for All Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8757369-62f3-4aa0-81e6-b349b075a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d87830-35f2-4b88-84c7-c5285160fb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate the file path where the audio is. AUDIO SHOULD BE SINGLE CHANNEL        \n",
    "aint_audio_file_path = \"path\"\n",
    "\n",
    "be_audio_file_path = \"path\"\n",
    "\n",
    "done_audio_file_path = \"path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982462d-5d1f-42be-a17b-6c3729ab1284",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath for the csv produced in Step 2.3\n",
    "aint_file_path = \"path\"\n",
    "\n",
    "be_file_path = \"path\"\n",
    "\n",
    "done_file_path = \"path\"\n",
    "\n",
    "#reads in the gold standard dataframe    \n",
    "aint_gs_df = pd.read_csv(aint_file_path)\n",
    "\n",
    "be_gs_df = pd.read_csv(be_file_path)\n",
    "\n",
    "done_gs_df = pd.read_csv(done_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5303be2b-8ce3-4091-a978-24753cc6be83",
   "metadata": {},
   "source": [
    "# 1. Amazon Transcribe\n",
    "\n",
    "These instructions assume you have set up an Amazon Transcribe account. Use this [link](https://aws.amazon.com/getting-started/hands-on/create-audio-transcript-transcribe/) for help with start-up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a886bb20-94ee-4999-8478-041c615f774a",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "This code is adapted directly from the work of two developers:\n",
    "\n",
    "1. [Viet Hoang Tran Duong](https://github.com/viethoangtranduong) (code [here](https://github.com/viethoangtranduong/AWS-Transcribe-Tutorial/blob/master/AWS_Transcribe_Tutorial.ipynb))\n",
    "2. [Rekhu Gopal](https://github.com/RekhuGopal) (code [here](https://github.com/RekhuGopal/PythonHacks/blob/main/AWSBoto3Hacks/AWSboto3SpeechToText-AWSTranscribe.py))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e169169-b967-4d9d-8eea-dc039cc7ebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "import time\n",
    "import boto3\n",
    "import urllib\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd44c9b-a932-4042-81d8-260d4b72c397",
   "metadata": {},
   "source": [
    "## 1.0 Uploading Data to the Amazon Web Services Console\n",
    "\n",
    "Before running transcription services, your data must be uploaded to your Amazon S3 Web Services Console. To do so, either (1) follow these steps to use the Amazon Console through a browser:\n",
    "\n",
    "1. Go to https://s3.console.aws.amazon.com/s3.\n",
    "    - Click 'Create Bucket'.\n",
    "    - Name the bucket.\n",
    "    - Set the region (I left it on the default).\n",
    "    - Make sure 'Block all public access' is checked.\n",
    "    - Choose whether you would like bucket versioning disabled or enabled.\n",
    "    - Add tags if you like.\n",
    "    - Choose whether to enable or disable encryption.\n",
    "    - Click 'Create Bucket'.\n",
    "2. Find your newly created bucket in the list and click the bucket name.\n",
    "3. Upload audio files here.\n",
    "\n",
    "Or (2) run the following code to upload directly from your local machine. If you use this method, you'll have to run it for each folder of data to upload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c2cba1-e1a0-4366-a493-f6785bb7527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3', \n",
    "                  aws_access_key_id = \"key_id\",\n",
    "                  aws_secret_access_key = \"access_key\",\n",
    "                          \n",
    "                  #the region of the data center\n",
    "                  region_name = \"region\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863dbae4-e8a0-44bb-86bf-d1a14649cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the file path of the files you want to upload\n",
    "filepath = \"path\"\n",
    "\n",
    "# creates a list of files to be uploaded\n",
    "amazon_files = os.listdir(filepath)\n",
    "\n",
    "## if you would like a progress flag, uncomment this line along with the last two lines in the for loop\n",
    "#iteration_number = 1\n",
    "\n",
    "# loops through the files to be uploaded and uploads them\n",
    "for amazon_file in amazon_files:\n",
    "    \n",
    "    # the arguments here are:\n",
    "    #  (1) the file path of the file to be uploaded,\n",
    "    #  (2) the Amazon s3 Cloud storage bucket name,\n",
    "    #  (3) the file name of the file to be uploaded (which is called the Key in the boto3 code\n",
    "    \n",
    "    s3.upload_file(f\"{path}{amazon_file}\", 'coraal-aint-variations-2021-amazon', f\"{amazon_file}\")\n",
    "    \n",
    "#     print(f\"{iteration_number}/{len(amazon_files)} completed. {amazon_file}\")\n",
    "          \n",
    "#     iteration_number+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef73b6a0-654e-4372-befb-aac75f7c939d",
   "metadata": {},
   "source": [
    "One more thing to consider is that when an Amazon Transcription job already has the same name as a file you want to process, it will cause the code to throw an error. It may be a good idea to copy the audio snippet files and append a *_aint*, *_be*, or *_done* to the end and upload that. That will help to solve the issue in case there is overlap between the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d3153c-4fb1-4e93-9cf9-fcf448e03344",
   "metadata": {},
   "source": [
    "## 1.1 Set up the Connection to Amazon Transcribe\n",
    "\n",
    "To set up the initial connection, you will need two keys: (1) Access Key ID, and (2) Secret Access Key. To do so, follow these steps:\n",
    "\n",
    "1. Go to https://console.aws.amazon.com/ and log into your account.\n",
    "2. In the top right corner, click on your Amazon profile name.\n",
    "3. Click 'My Security Credentials'.\n",
    "4. Click 'Access keys'.\n",
    "5. If you already have access keys, take them from here (make sure they are active).\n",
    "    - If not, click 'Create New Access Key'. You can then download a CSV with the keys or copy them directly from the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c295c92b-38a0-4eae-bfa6-1ff0b22ebbbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sets up the connection to the Amazon Transcribe (Amazon Web Services)\n",
    "transcribe = boto3.client('transcribe',\n",
    "                          aws_access_key_id = \"key_id\",\n",
    "                          aws_secret_access_key = \"access_key\",\n",
    "                          \n",
    "                          #the region of the data center\n",
    "                          region_name = \"region\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf4d7c-1ea1-4c46-9148-f3f109e17145",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.2 Defining the Job Checker Function\n",
    "\n",
    "Amazon Transcribe works on jobs. If you try to create a job with the same name as another, it will need to override the previous one. This code will check if the job exists and, if so, override it so the ASR service can be run.\n",
    "\n",
    "This function takes the following arguments:\n",
    "1. Job name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce251fb7-e742-42af-b308-2662048741ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_job_name(job_name):\n",
    "    \n",
    "    \"\"\"\n",
    "    when Amazon Transcribe transcribes audio, it creates a job and each job must have\n",
    "    a unique name. This function checks if the job name has already been used and if so\n",
    "    asks if the user would like to override that job\n",
    "    \"\"\"\n",
    "    \n",
    "    #lists the jobs currently in the console\n",
    "    # you can also delete jobs manually by going to the transcription jobs\n",
    "    #  in the console: https://us-east-2.console.aws.amazon.com/transcribe/\n",
    "    existing_jobs = transcribe.list_transcription_jobs()\n",
    "    \n",
    "    #loops through the existing job names\n",
    "    for job in existing_jobs['TranscriptionJobSummaries']:\n",
    "        \n",
    "        #if the name of the job name given already exists, this will delete the job\n",
    "        #  and create a new one with that name\n",
    "        if job_name == job['TranscriptionJobName']:\n",
    "            \n",
    "            #delete the job\n",
    "            transcribe.delete_transcription_job(TranscriptionJobName=job_name)\n",
    "        \n",
    "        #if a job with that name doesn't exist, continues past \n",
    "        else:\n",
    "            \n",
    "            continue\n",
    "    \n",
    "    #returns the job name\n",
    "    # this will be the one provided to the function whether the job already\n",
    "    #  existed in the Amazon Transcribe console or not\n",
    "    return job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27beebd6-c9e6-479f-a252-17fb962db07e",
   "metadata": {},
   "source": [
    "## 1.3 Defining the Transcriber Function\n",
    "\n",
    "This code will define the function that runs the transcriber.\n",
    "\n",
    "This function takes the following arguments:\n",
    "1. The path to the S3 Bucket you created in 1.0 above. To find this path:\n",
    "    - Go to https://s3.console.aws.amazon.com.\n",
    "    - Click Buckets.\n",
    "    - Find the bucket where your data is (or create a bucket and store the data).\n",
    "    - Copy the s3 path (you'll probably have to go to an individual file, copy the S3 path, paste it, and chop off the audio file name).\n",
    "2. The audio file name (taken from the dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6061aa-ed79-473f-b00a-f491e81623df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this creates the function that will run the Amazon Transcription service\n",
    "# this is tuned to identify multiple speakers for optimal transciption\n",
    "def amazon_transcribe(s3_bucket_path, audio_file_name):\n",
    "    \n",
    "    \"\"\"\n",
    "    takes the variables:\n",
    "    (1) audio_file_name which is the audio filename\n",
    "    (2) s3_bucket_path which is the path to the audio files stored\n",
    "        in Amazon's s3 cloud storage. Go to https://s3.console.aws.amazon.com >>\n",
    "        Buckets >> Find the bucket where your data is (or create a bucket and store the data) >>\n",
    "        Copy the s3 path (you'll probably have to go to an individual file and copy the s3\n",
    "        path that way, paste it here and chop off the audio file name\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #combines the s3 bucket path with the audio file name to create the job URI\n",
    "    job_uri = s3_bucket_path + audio_file_name\n",
    "    \n",
    "    #creates a variable with the audio filename to use as the job name\n",
    "    job_name = (audio_file_name.split('.')[0]).replace(\" \", \"\")\n",
    "  \n",
    "    # check if name is taken or not\n",
    "    job_name = check_job_name(job_name)\n",
    "  \n",
    "    # file format of the audio file (Should be .wav for best results)\n",
    "    file_format = audio_file_name.split('.')[1]\n",
    "\n",
    "    #transcribe the audio\n",
    "    transcribe.start_transcription_job(\n",
    "      TranscriptionJobName=job_name,\n",
    "      Media={'MediaFileUri': job_uri},\n",
    "      MediaFormat = file_format,\n",
    "      LanguageCode='en-US')\n",
    "\n",
    "    \n",
    "    #parses the results from the speech to text\n",
    "    while True:\n",
    "        result = transcribe.get_transcription_job(TranscriptionJobName=job_name)\n",
    "        \n",
    "        #checks the status of the job\n",
    "        if result['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "            \n",
    "            #if the status is either COMPLETED or FAILED, breaks the loop\n",
    "            break\n",
    "        \n",
    "        # waits 15 seconds before looping again (if the loop hasn't been broken)\n",
    "        time.sleep(15)\n",
    "    \n",
    "    \n",
    "    #if the result is completed rather than failed, accesses the information\n",
    "    if result['TranscriptionJob']['TranscriptionJobStatus'] == 'COMPLETED':\n",
    "        \n",
    "        #the transcription is actually stored online, so to get it directly in the code\n",
    "        #  it is necessary to use urllib to access the json file which stores it\n",
    "        response = urllib.request.urlopen(result['TranscriptionJob']['Transcript']['TranscriptFileUri'])\n",
    "        \n",
    "        #reads and stores the complete json file data\n",
    "        data = json.loads(response.read())\n",
    "        \n",
    "        #gets only the transcript text\n",
    "        text = data['results']['transcripts'][0]['transcript']\n",
    "    \n",
    "    \n",
    "    #if the result is failed rather than completed, returns an empty string\n",
    "    elif result['TranscriptionJob']['TranscriptionJobStatus'] == 'FAILED':\n",
    "        \n",
    "        #reads and stores the complete json file data\n",
    "        #only use this if you want to return the data anyways\n",
    "        #data = json.loads(response.read())\n",
    "        \n",
    "        #creates an empty string\n",
    "        text = \"\"\n",
    "        \n",
    "        #returns an empty string\n",
    "        return text\n",
    "    \n",
    "        #if you want to return the data, uncomment the data statement above and use this return statement\n",
    "        #return data, text\n",
    "    \n",
    "    #returns the transcription text\n",
    "    return text\n",
    "\n",
    "    #if you want both the whole json and the transcription text, use this return statement\n",
    "    # you'll just need to adjust the code below to return the data variable to get the json\n",
    "    # the json file can be written out to a json file or the text of it can be appended to the dataframe\n",
    "#     return data, text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e4b31e-b525-49c3-9d97-35876dbe0dbc",
   "metadata": {},
   "source": [
    "## 1.4 Executing the Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b46ae32-9c70-4192-bada-5b5ce23921ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path to the Amazon s3 cloud storage which is the path to the audio files stored\n",
    "#     in Amazon's s3 cloud storage. Go to https://s3.console.aws.amazon.com >>\n",
    "#     Buckets >> Find the bucket where your data is (or create a bucket and store the data) >>\n",
    "#     Copy the s3 path (you'll probably have to go to an individual file and copy the s3\n",
    "#     path that way, paste it here and chop off the audio file name\n",
    "\n",
    "aint_s3_bucket_path = \"path\"\n",
    "\n",
    "be_s3_bucket_path = \"path\"\n",
    "\n",
    "done_s3_bucket_path = \"path\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94261d67-6da9-4c38-8d69-f74e65d85a24",
   "metadata": {},
   "source": [
    "### Feature: Ain't"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbda8ddc-9a9b-4b1e-9579-5244dd50a64a",
   "metadata": {},
   "source": [
    "Before you run the Amazon code for *ain't* variations, you'll want to reorder your dataframe to put duplicate rows on the bottom. If the code runs into a duplicate File and Line, it won't delete the previous job already processed and will throw an error and stop the code. The following cell will do that for you before you run the transcriber."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a273b8-c25a-46eb-904c-2c135b62ee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a dataframe of only duplicated lines\n",
    "duplicates_df = aint_gs_df[aint_gs_df.duplicated(['File', 'Line'])]\n",
    "\n",
    "# creates a dataframe with no duplicated lines\n",
    "no_duplicates_df = aint_gs_df[~aint_gs_df.duplicated(['File', 'Line'])]\n",
    "\n",
    "# concatenates the two dataframes with the duplicates last\n",
    "aint_gs_df = pd.concat([no_duplicates_df, duplicates_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f478856-fa52-421a-b7cb-26e72a9cdbc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creates a column for the ibm transcripts\n",
    "aint_gs_df['amazon_transcription'] = np.nan\n",
    "\n",
    "## enable this if you'd like to print a message that will show the progress\n",
    "#iteration_number = 1\n",
    "\n",
    "#cycles through the dataframe rows\n",
    "for file_row in aint_gs_df.itertuples():\n",
    "    \n",
    "    #creates a variable with the filename\n",
    "    # here i've adjusted for my 16khz files. If you don't need this, use the commented out line\n",
    "    audio_filename = f\"16khz_{file_row.File}_Line{file_row.Line}_FeatCount{file_row.FeatureCountPerLine}.wav\"\n",
    "    ## if you uploaded different file names, use this:\n",
    "    # audio_filename = f\"16khz_{file_row.File}_Line{file_row.Line}_FeatCount{file_row.FeatureCountPerLine}_aint.wav\"\n",
    "\n",
    "    #run the code and get transcription\n",
    "    transcription = amazon_transcribe(aint_s3_bucket_path, audio_filename)\n",
    "    \n",
    "    #writes the transcription to the dataframe\n",
    "    aint_gs_df.loc[file_row.Index, \"amazon_transcription\"] = transcription\n",
    "    \n",
    "    ##enable this if you'd like to print a message that will show the progress\n",
    "    #print(f\"{iteration_number} / {len(aint_gs_df)} completed.\")\n",
    "        \n",
    "    #iteration_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1042749-b760-449c-a0ff-adbdad348280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorts the data frame back to the correct order for the rest of the transcribers\n",
    "aint_gs_df = aint_gs_df.sort_values(by=['File', 'Line'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fa6045-91fa-49cb-b9bf-2046085a62b1",
   "metadata": {},
   "source": [
    "## Feature: Be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e42589-5097-401e-9ebd-ded0b1a8ea66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creates a column for the ibm transcripts\n",
    "# be_gs_df['amazon_transcription'] = np.nan\n",
    "\n",
    "## enable this if you'd like to print a message that will show the progress\n",
    "#iteration_number = 1\n",
    "\n",
    "#cycles through the dataframe rows\n",
    "for file_row in be_gs_df.itertuples():\n",
    "    \n",
    "    #creates a variable with the filename\n",
    "    # here i've adjusted for my 16khz files. If you don't need this, use the commented out line\n",
    "    audio_filename = f\"16khz_{file_row.File}_Line{file_row.Line}_FeatCount{file_row.FeatureCountPerLine}.wav\"\n",
    "    ## if you uploaded different file names, use this:\n",
    "    # audio_filename = f\"16khz_{file_row.File}_Line{file_row.Line}_FeatCount{file_row.FeatureCountPerLine}_be.wav\"\n",
    "    \n",
    "    \n",
    "    #run the code and get transcription\n",
    "    transcription = amazon_transcribe(be_s3_bucket_path, audio_filename)\n",
    "    \n",
    "    #writes the transcription to the dataframe\n",
    "    be_gs_df.loc[file_row.Index, \"amazon_transcription\"] = transcription\n",
    "    \n",
    "    ##enable this if you'd like to print a message that will show the progress\n",
    "    #print(f\"{iteration_number} / {len(be_gs_df)-755} completed.\")\n",
    "        \n",
    "    #iteration_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384cab84-16da-450c-834f-8e10d75c0d64",
   "metadata": {},
   "source": [
    "## Feature: Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051e1063-dfb4-48aa-8cc1-3ae535ef2304",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creates a column for the ibm transcripts\n",
    "done_gs_df['amazon_transcription'] = np.nan\n",
    "\n",
    "# enable this if you'd like to print a message that will show the progress\n",
    "iteration_number = 1\n",
    "\n",
    "#cycles through the dataframe rows\n",
    "for file_row in done_gs_df.itertuples():\n",
    "    \n",
    "    #creates a variable with the filename\n",
    "    # here i've adjusted for my 16khz files. If you don't need this, use the commented out line\n",
    "    audio_filename = f\"16khz_{file_row.File}_Line{file_row.Line}_FeatCount{file_row.FeatureCountPerLine}.wav\"\n",
    "    ## if you uploaded different file names, use this:\n",
    "    # audio_filename = f\"16khz_{file_row.File}_Line{file_row.Line}_FeatCount{file_row.FeatureCountPerLine}_done.wav\"\n",
    "    \n",
    "    \n",
    "    #run the code and get transcription\n",
    "    transcription = amazon_transcribe(done_s3_bucket_path, audio_filename)\n",
    "    \n",
    "    #writes the transcription to the dataframe\n",
    "    done_gs_df.loc[file_row.Index, \"amazon_transcription\"] = transcription\n",
    "    \n",
    "    #enable this if you'd like to print a message that will show the progress\n",
    "    print(f\"{iteration_number} / {len(done_gs_df)} completed.\")\n",
    "        \n",
    "    iteration_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5506c4a3-1c86-4105-af01-e3f97c233490",
   "metadata": {},
   "source": [
    "# 2. DeepSpeech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70c3cfc-6f8f-4b5d-9217-9832810b197b",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "This code is adapted directly from the code presented in the following video:\n",
    "\n",
    "1. https://www.youtube.com/watch?v=iWha--55Lz0\n",
    "\n",
    "Helpful links:\n",
    "\n",
    "- https://scgupta.medium.com/how-to-build-python-transcriber-using-mozilla-deepspeech-5485b8d234cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59b77e1-848a-4ddf-806e-bc93e715ef24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "from deepspeech import Model\n",
    "import wave"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955ba36c-3bad-421e-9c84-7a0fe2a1856f",
   "metadata": {},
   "source": [
    "## 2.1 Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4a4448-f073-4f0b-93e8-a00c1554a4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sets the model path\n",
    "model_file_path = \"deepspeech-0.9.3-models.pbmm\"\n",
    "\n",
    "#sets the scorer path\n",
    "lm_file_path = \"deepspeech-0.9.3-models.scorer\"\n",
    "\n",
    "#creates an instance of the model\n",
    "model = Model(model_file_path)\n",
    "\n",
    "#enables the scorer\n",
    "model.enableExternalScorer(lm_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f1bd54-14d3-4d18-aacf-8af001f75e47",
   "metadata": {},
   "source": [
    "## 2.2 Defining the Wave File Reader Function\n",
    "\n",
    "This code will define a function to read the wave file. This function is defined here in order to be used within the next function.\n",
    "\n",
    "**NOTE**: Files for DeepSpeech must have a sampling rate of 16khz. All files for CORAAL are 44.1khz and need to be resampled to 16khz. Please refer to Step 2.1 for instructions on how to do that.\n",
    "\n",
    "This function takes the following arguments:\n",
    "1. The filename of the wave file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3001dd75-5b00-45af-acfa-f42d6981e84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wave_file(filename):\n",
    "    \n",
    "    #open the file\n",
    "    with wave.open(filename, 'rb') as w:\n",
    "        \n",
    "        #get frame rate\n",
    "        rate = w.getframerate()\n",
    "        \n",
    "        #get number of frames\n",
    "        frames = w.getnframes()\n",
    "        \n",
    "        #get buffer\n",
    "        buffer = w.readframes(frames)\n",
    "        \n",
    "        #return buffer and rate\n",
    "        return buffer, rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293456a1-0984-4069-9d9a-91c3ac5b17ed",
   "metadata": {},
   "source": [
    "## 2.3 Defining the Transcriber Function\n",
    "\n",
    "This code will define a function that runs the transcriber.\n",
    "\n",
    "This function will return two variables:\n",
    "1. The transcript from the speech to text\n",
    "2. The confidence value\n",
    "    - NOTE: The confidence value here is not measured in the way that the other services do. The other services use a probability measure of 0 to 1. Deepspeech's confidence value can be huge numbers beyond 0 and 1. The confidence value here is more meant to compare two alternatives within Deepspeech itself and may have no comparable value outside of DeepSpeech. I will record it for information sake, but be cautious in using it to measure anything. Here's the official explanation for that: https://github.com/mozilla/DeepSpeech/issues/2053\n",
    "\n",
    "This function takes the following arguments:\n",
    "1. The audio filepath defined above\n",
    "2. The filename of the wave file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cb7321-994e-4405-a422-9d8d7192288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepspeech_transcribe(audio_filepath, audio_filename):\n",
    "    \n",
    "    buffer, rate = read_wave_file(f\"{audio_filepath}{audio_filename}\")\n",
    "    \n",
    "    data16 = np.frombuffer(buffer, dtype=np.int16)\n",
    "    \n",
    "    return model.stt(data16), model.sttWithMetadata(data16).transcripts[0].confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9da17b-f8e7-4996-9f4c-f8f865edac35",
   "metadata": {},
   "source": [
    "## 2.4 Executing the Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b26f69-f0cb-466c-a846-bbc1c145e605",
   "metadata": {},
   "source": [
    "### Feature: Ain't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4892e6e3-e521-4a4a-9e95-847470d534d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creates a column for the transcripts\n",
    "aint_gs_df['deepspeech_transcription'] = np.nan\n",
    "\n",
    "#creates a column for the confidence level\n",
    "aint_gs_df['deepspeech_ConfidenceLevel'] = np.nan\n",
    "\n",
    "#enable this if you'd like to print a message that will the progress\n",
    "# iteration_number = 1\n",
    "\n",
    "#cycles through the dataframe rows\n",
    "for file_row in aint_gs_df.itertuples():\n",
    "    \n",
    "    #creates a variable with the filename\n",
    "    # here i've adjusted for my 16khz files. If you don't need this, use the commented out line\n",
    "    filename = f\"16khz_{file_row.File}_Line{file_row.Line}_FeatCount{file_row.FeatureCountPerLine}.wav\"\n",
    "    \n",
    "    #performs the speech to text and returns the transcription and the confidence value\n",
    "    transcription, confidence_value = deepspeech_transcribe(aint_audio_file_path, filename)\n",
    "\n",
    "    #writes the text to the dataframe\n",
    "    aint_gs_df.loc[file_row.Index, \"deepspeech_transcription\"] = transcription\n",
    "\n",
    "    #writes the confidence level to the dataframe\n",
    "    aint_gs_df.loc[file_row.Index, \"deepspeech_ConfidenceLevel\"] = confidence_value\n",
    "    \n",
    "#     #enable this if you'd like to print a message that will show the progress\n",
    "#     print(f\"{iteration_number} / {len(aint_gs_df)} completed.\")\n",
    "        \n",
    "#     iteration_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86078189-fff6-40b5-8ccf-a874d90ba814",
   "metadata": {},
   "source": [
    "### Feature: Be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b8c4b7-3a93-44f6-9032-d77f7f57e2f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creates a column for the transcripts\n",
    "be_gs_df['deepspeech_transcription'] = np.nan\n",
    "\n",
    "#creates a column for the confidence level\n",
    "be_gs_df['deepspeech_ConfidenceLevel'] = np.nan\n",
    "\n",
    "## enable this if you'd like to print a message that will show the progress\n",
    "#iteration_number = 1\n",
    "\n",
    "#cycles through the dataframe rows\n",
    "for file_row in be_gs_df.itertuples():\n",
    "    \n",
    "    #creates a variable with the filename\n",
    "    # here i've adjusted for my 16khz files. If you don't need this, use the commented out line\n",
    "    filename = f\"16khz_{file_row.File}_Line{file_row.Line}_FeatCount{file_row.FeatureCountPerLine}.wav\"\n",
    "    \n",
    "    #performs the speech to text and returns the transcription and the confidence value\n",
    "    transcription, confidence_value = deepspeech_transcribe(be_audio_file_path, filename)\n",
    "\n",
    "    #writes the text to the dataframe\n",
    "    be_gs_df.loc[file_row.Index, \"deepspeech_transcription\"] = transcription\n",
    "\n",
    "    #writes the confidence level to the dataframe\n",
    "    be_gs_df.loc[file_row.Index, \"deepspeech_ConfidenceLevel\"] = confidence_value\n",
    "    \n",
    "    ##enable this if you'd like to print a message that will show the progress\n",
    "    #print(f\"{iteration_number} / {len(be_gs_df)} completed.\")\n",
    "        \n",
    "    #iteration_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c0995e-2057-462a-a79e-a5f9cb979659",
   "metadata": {},
   "source": [
    "### Feature: Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fbf315-7222-4b21-9161-9594e9ecd5e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creates a column for the transcripts\n",
    "done_gs_df['deepspeech_transcription'] = np.nan\n",
    "\n",
    "#creates a column for the confidence level\n",
    "done_gs_df['deepspeech_ConfidenceLevel'] = np.nan\n",
    "\n",
    "# # enable this if you'd like to print a message that will show the progress\n",
    "# iteration_number = 1\n",
    "\n",
    "#cycles through the dataframe rows\n",
    "for file_row in done_gs_df.itertuples():\n",
    "    \n",
    "    #creates a variable with the filename\n",
    "    # here i've adjusted for my 16khz files. If you don't need this, use the commented out line\n",
    "    filename = f\"16khz_{file_row.File}_Line{file_row.Line}_FeatCount{file_row.FeatureCountPerLine}.wav\"\n",
    "    \n",
    "    #performs the speech to text and returns the transcription and the confidence value\n",
    "    transcription, confidence_value = deepspeech_transcribe(done_audio_file_path, filename)\n",
    "\n",
    "    #writes the text to the dataframe\n",
    "    done_gs_df.loc[file_row.Index, \"deepspeech_transcription\"] = transcription\n",
    "\n",
    "    #writes the confidence level to the dataframe\n",
    "    done_gs_df.loc[file_row.Index, \"deepspeech_ConfidenceLevel\"] = confidence_value\n",
    "    \n",
    "#     #enable this if you'd like to print a message that will show the progress\n",
    "#     print(f\"{iteration_number} / {len(done_gs_df)} completed.\")\n",
    "        \n",
    "#     iteration_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99553449-b449-4196-a0f6-5906a366ed55",
   "metadata": {},
   "source": [
    "# 3. Google Cloud Speech-to-Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57208c8e-3fc3-4d2e-92bb-696baf5515fe",
   "metadata": {},
   "source": [
    "This code assumes you have set-up a Google Cloud account. Follow the steps listed [here](https://cloud.google.com/speech-to-text/docs/before-you-begin) for start-up help.\n",
    "\n",
    "**Note:** If you run into a permissions error, it probably says this: \"PermissionDenied: 403 _____@_______.iam.gserviceaccount.com does not have storage.objects.get access to the Google Cloud Storage object.\" Copy the email address in this error message, and then follow the directions here: https://cloud.google.com/storage/docs/access-control/using-iam-permissions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18db338-0e0c-4537-916d-fe47d50fb1bc",
   "metadata": {},
   "source": [
    "# 3.0 Uploading Data to Google Cloud Storage\n",
    "\n",
    "Before running transcription services, your data must be uploaded to your Google Cloud Console. To do so, follow these steps:\n",
    "\n",
    "1. Go to https://console.cloud.google.com/storage/browser.\n",
    "    - Click 'Create Bucket'.\n",
    "    - Name the bucket.\n",
    "    - Set the region (I selected single region and left it on the default).\n",
    "    - Choose a default storage class for your data.\n",
    "    - Ensure \"Enforce public access prevention on this bucket\" is clicked.\n",
    "    - Choose the encryption you want (I left it on default).\n",
    "    - Click 'Create'.\n",
    "2. Upload audio files in the bucket which should pop up once you click create."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9d9679-5709-4660-a25e-2da8983f212a",
   "metadata": {},
   "source": [
    "# 3.1 Initial Set-up\n",
    "\n",
    "To connect to the Google Cloud Speech-to-Text service, you must have a credential path. The credential is a json file which you download to your computer and then insert the file path to that json in the code below. To do this, follow the steps here: https://cloud.google.com/speech-to-text/docs/before-you-begin (especially [this section](https://cloud.google.com/speech-to-text/docs/before-you-begin#creating_a_json_key_for_your_service_account))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcac4b9-03d3-4b29-87db-35f2f0ad45f5",
   "metadata": {},
   "source": [
    "# 3.2 Defining the Transcriber Function\n",
    "\n",
    "This code will define a function that runs the transcriber. It will return the transcription and write to the dataframe.\n",
    "\n",
    "This function takes two arguments:\n",
    "1. The file path to the audio file in Google Cloud storage. This is the directory of your audio files' bucket folder.\n",
    "2. The audio filename (which will be taken from the dataframe).\n",
    "\n",
    "**IMPORTANT NOTE:** You must change the credential_path variable in the function code here in order for the code to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc826f93-f55b-429f-8eec-f469af659e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_gcs(gcs_uri_path, gcs_uri_filename):\n",
    "    \n",
    "    \"\"\"Asynchronously transcribes the audio file specified by the gcs_uri.\"\"\"\n",
    "    \n",
    "    import os\n",
    "    \n",
    "    from google.cloud import speech\n",
    "    \n",
    "    #this is taken from the Google Cloud Project with the correct API\n",
    "    #it will have to change depending on the user\n",
    "    credential_path = \"path\"\n",
    "    \n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credential_path\n",
    "    \n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    #I ran into a lot of issues here. If you use help(speech.RecongitionConfig) it helps\n",
    "    audio = speech.RecognitionAudio(uri=gcs_uri_path+gcs_uri_filename)\n",
    "    \n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        language_code=\"en-US\",\n",
    "        enable_automatic_punctuation=True,\n",
    "    )\n",
    "\n",
    "    operation = client.long_running_recognize(config=config, audio=audio)\n",
    "    \n",
    "#     enable this if you want a flag to print\n",
    "#     print(\"Waiting for operation to complete...\")\n",
    "    \n",
    "    response = operation.result(timeout=90)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177c8f36-ec2b-4118-b729-c75fbd1b9bdb",
   "metadata": {},
   "source": [
    "## 3.3 Executing the Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543c91da-78e5-4909-8b9f-d5a97aa0f58b",
   "metadata": {},
   "source": [
    "### Feature: Ain't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef2f47c-01e1-462d-9cca-ad3ea97b51ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this is the path in the google cloud storage\n",
    "#google cloud storage MUST be used for files longer than a minute\n",
    "#only files under a minute can be processed locally\n",
    "# store files in Google Cloud Platform storage here: https://console.cloud.google.com/storage/browser\n",
    "aint_gcs_uri_path = \"path\"\n",
    "\n",
    "\n",
    "#creates a column for the ibm transcripts\n",
    "aint_gs_df['google_transcription'] = np.nan\n",
    "\n",
    "#creates a column for the ibm confidence level\n",
    "aint_gs_df['google_ConfidenceLevel'] = np.nan\n",
    "\n",
    "## enable this if you'd like to print a message that will show the progress\n",
    "# iteration_number = 1\n",
    "\n",
    "#cycles through the dataframe rows\n",
    "for file_row in aint_gs_df.itertuples():\n",
    "    \n",
    "    #creates a variable with the filename\n",
    "    # here i've adjusted for my 16khz files. If you don't need this, use the commented out line\n",
    "    filename = f\"16khz_{file_row.File}_Line{file_row.Line}_FeatCount{file_row.FeatureCountPerLine}.wav\"\n",
    "    \n",
    "    #performs the transcription\n",
    "    file_response = transcribe_gcs(aint_gcs_uri_path, filename)\n",
    "    \n",
    "    #if the service isn't able to produce a transcript, writes a NaN to the dataframe\n",
    "    if len(file_response.results) == 0:\n",
    "        \n",
    "        aint_gs_df.loc[file_row.Index, \"google_transcription\"] = \"\"\n",
    "\n",
    "        #writes a zero level confidence to the dataframe\n",
    "        aint_gs_df.loc[file_row.Index, \"google_ConfidenceLevel\"] = 0\n",
    "\n",
    "    else:\n",
    "\n",
    "        #if the result only has one transcript, writes the transcript to the dataframe\n",
    "        if len(file_response.results) == 1:\n",
    "\n",
    "            # this is coded this way because of the structure of the json\n",
    "            #   res is the json object, which is essentially a python dictionary in this context\n",
    "            #   res['results'] opens the value paired with the key 'results' which is\n",
    "            #   a list of the results. [0] gets the first item which is another dictionary\n",
    "            #   which contains a list of alternatives. since there is only one here, the [0]\n",
    "            #   is used to get the first entry which is a dictionary with a 'transcript' key\n",
    "            #   and the ASR transcribed speech as the value\n",
    "            text = file_response.results[0].alternatives[0].transcript\n",
    "\n",
    "            #writes the text to the dataframe\n",
    "            aint_gs_df.loc[file_row.Index, \"google_transcription\"] = text\n",
    "\n",
    "            #creates a variable for the confidence level\n",
    "            # this could be written into the next line, but coding it this way\n",
    "            #  makes the code more readable and understandable for me\n",
    "            confidence_level = file_response.results[0].alternatives[0].confidence\n",
    "\n",
    "            #writes the confidence level to the dataframe\n",
    "            aint_gs_df.loc[file_row.Index, \"google_ConfidenceLevel\"] = confidence_level\n",
    "\n",
    "        else:\n",
    "\n",
    "            #if there are multiple alternatives, this code will find the alternative with the\n",
    "            #  highest confidence level and take that as the transcript\n",
    "\n",
    "            #creates an empty list to append tuples to\n",
    "            tuples_list = []\n",
    "\n",
    "            #cycles through the list of results in the res variable\n",
    "            for result in file_response.results:\n",
    "\n",
    "                # for each result, creates a tuple of the confidence level and index of each result in the lisit\n",
    "                confidence_index = (result.alternatives[0].confidence, file_response.results.index(result))\n",
    "\n",
    "                # appends the tuple to the list\n",
    "                tuples_list.append(confidence_index)\n",
    "\n",
    "            #performs the same function as the text= variable in the previous step, except here,\n",
    "            #  the first [0] is replaced with [max(tuples_list)[1]]. What this does is\n",
    "            #  takes the maximum confidence level in the tuples_list by taking the max\n",
    "            #  number in all of the first items in each tuple and then takes the index\n",
    "            #  from the max tuple by accessing its second item, and uses that index\n",
    "            #  as the index for the larger results list\n",
    "            text = file_response.results[max(tuples_list)[1]].alternatives[0].transcript\n",
    "\n",
    "            #writes the text to the dataframe\n",
    "            aint_gs_df.loc[file_row.Index, \"google_transcription\"] = text\n",
    "\n",
    "            #creates a variable for the confidence level\n",
    "            # this could be written into the next line, but coding it this way\n",
    "            #  makes the code more readable and understandable for me\n",
    "            confidence_level = file_response.results[max(tuples_list)[1]].alternatives[0].confidence\n",
    "\n",
    "            #writes the confidence level to the dataframe\n",
    "            aint_gs_df.loc[file_row.Index, \"google_ConfidenceLevel\"] = confidence_level\n",
    "            \n",
    "    ##enable this if you'd like to print a message that will show the progress\n",
    "    #print(f\"{iteration_number} / {len(aint_gs_df)} completed.\")\n",
    "        \n",
    "    #iteration_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7153f7a9-72a6-46c0-a5d0-40c5550d7256",
   "metadata": {},
   "source": [
    "### Feature: Be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc87e2af-61a4-41b1-b39b-b617edaf8a49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this is the path in the google cloud storage\n",
    "#google cloud storage MUST be used for files longer than a minute\n",
    "#only files under a minute can be processed locally\n",
    "# store files in Google Cloud Platform storage here: https://console.cloud.google.com/storage/browser\n",
    "be_gcs_uri_path = \"path\"\n",
    "\n",
    "\n",
    "#creates a column for the ibm transcripts\n",
    "be_gs_df['google_transcription'] = np.nan\n",
    "\n",
    "#creates a column for the ibm confidence level\n",
    "be_gs_df['google_ConfidenceLevel'] = np.nan\n",
    "\n",
    "\n",
    "## enable this if you'd like to print a message that will show the progress\n",
    "#iteration_number = 1\n",
    "\n",
    "\n",
    "#cycles through the dataframe rows\n",
    "for file_row in be_gs_df.itertuples():\n",
    "    \n",
    "    #creates a variable with the filename\n",
    "    # here i've adjusted for my 16khz files. If you don't need this, use the commented out line\n",
    "    filename = f\"16khz_{file_row.File}_Line{file_row.Line}_FeatCount{file_row.FeatureCountPerLine}.wav\"\n",
    "    \n",
    "    #performs the transcription\n",
    "    file_response = transcribe_gcs(be_gcs_uri_path, filename)\n",
    "    \n",
    "    #if the service isn't able to produce a transcript, writes a NaN to the dataframe\n",
    "    if len(file_response.results) == 0:\n",
    "        \n",
    "        be_gs_df.loc[file_row.Index, \"google_transcription\"] = \"\"\n",
    "\n",
    "        #writes a zero level confidence to the dataframe\n",
    "        be_gs_df.loc[file_row.Index, \"google_ConfidenceLevel\"] = 0\n",
    "\n",
    "    else:\n",
    "\n",
    "        #if the result only has one transcript, writes the transcript to the dataframe\n",
    "        if len(file_response.results) == 1:\n",
    "\n",
    "            # this is coded this way because of the structure of the json\n",
    "            #   res is the json object, which is essentially a python dictionary in this context\n",
    "            #   res['results'] opens the value paired with the key 'results' which is\n",
    "            #   a list of the results. [0] gets the first item which is another dictionary\n",
    "            #   which contains a list of alternatives. since there is only one here, the [0]\n",
    "            #   is used to get the first entry which is a dictionary with a 'transcript' key\n",
    "            #   and the ASR transcribed speech as the value\n",
    "            text = file_response.results[0].alternatives[0].transcript\n",
    "\n",
    "            #writes the text to the dataframe\n",
    "            be_gs_df.loc[file_row.Index, \"google_transcription\"] = text\n",
    "\n",
    "            #creates a variable for the confidence level\n",
    "            # this could be written into the next line, but coding it this way\n",
    "            #  makes the code more readable and understandable for me\n",
    "            confidence_level = file_response.results[0].alternatives[0].confidence\n",
    "\n",
    "            #writes the confidence level to the dataframe\n",
    "            be_gs_df.loc[file_row.Index, \"google_ConfidenceLevel\"] = confidence_level\n",
    "\n",
    "        else:\n",
    "\n",
    "            #if there are multiple alternatives, this code will find the alternative with the\n",
    "            #  highest confidence level and take that as the transcript\n",
    "\n",
    "            #creates an empty list to append tuples to\n",
    "            tuples_list = []\n",
    "\n",
    "            #cycles through the list of results in the res variable\n",
    "            for result in file_response.results:\n",
    "\n",
    "                # for each result, creates a tuple of the confidence level and index of each result in the lisit\n",
    "                confidence_index = (result.alternatives[0].confidence, file_response.results.index(result))\n",
    "\n",
    "                # appends the tuple to the list\n",
    "                tuples_list.append(confidence_index)\n",
    "\n",
    "            #performs the same function as the text= variable in the previous step, except here,\n",
    "            #  the first [0] is replaced with [max(tuples_list)[1]]. What this does is\n",
    "            #  takes the maximum confidence level in the tuples_list by taking the max\n",
    "            #  number in all of the first items in each tuple and then takes the index\n",
    "            #  from the max tuple by accessing its second item, and uses that index\n",
    "            #  as the index for the larger results list\n",
    "            text = file_response.results[max(tuples_list)[1]].alternatives[0].transcript\n",
    "\n",
    "            #writes the text to the dataframe\n",
    "            be_gs_df.loc[file_row.Index, \"google_transcription\"] = text\n",
    "\n",
    "            #creates a variable for the confidence level\n",
    "            # this could be written into the next line, but coding it this way\n",
    "            #  makes the code more readable and understandable for me\n",
    "            confidence_level = file_response.results[max(tuples_list)[1]].alternatives[0].confidence\n",
    "\n",
    "            #writes the confidence level to the dataframe\n",
    "            be_gs_df.loc[file_row.Index, \"google_ConfidenceLevel\"] = confidence_level\n",
    "            \n",
    "    ##enable this if you'd like to print a message that will show the progress\n",
    "    #print(f\"{iteration_number} / {len(be_gs_df)} completed.\")\n",
    "        \n",
    "    #iteration_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7c3107-38a1-4a99-bac4-40ff0e71cb6e",
   "metadata": {},
   "source": [
    "### Feature: Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43566f12-6a66-418b-bc1d-5723f0712079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this is the path in the google cloud storage\n",
    "#google cloud storage MUST be used for files longer than a minute\n",
    "#only files under a minute can be processed locally\n",
    "# store files in Google Cloud Platform storage here: https://console.cloud.google.com/storage/browser\n",
    "done_gcs_uri_path = \"path\"\n",
    "\n",
    "\n",
    "#creates a column for the ibm transcripts\n",
    "done_gs_df['google_transcription'] = np.nan\n",
    "\n",
    "#creates a column for the ibm confidence level\n",
    "done_gs_df['google_ConfidenceLevel'] = np.nan\n",
    "\n",
    "\n",
    "# # enable this if you'd like to print a message that will show the progress\n",
    "# iteration_number = 1\n",
    "\n",
    "\n",
    "#cycles through the dataframe rows\n",
    "for file_row in done_gs_df.itertuples():\n",
    "    \n",
    "    #creates a variable with the filename\n",
    "    # here i've adjusted for my 16khz files. If you don't need this, use the commented out line\n",
    "    filename = f\"16khz_{file_row.File}_Line{file_row.Line}_FeatCount{file_row.FeatureCountPerLine}.wav\"\n",
    "    \n",
    "    #performs the transcription\n",
    "    file_response = transcribe_gcs(done_gcs_uri_path, filename)\n",
    "    \n",
    "    #if the service isn't able to produce a transcript, writes a NaN to the dataframe\n",
    "    if len(file_response.results) == 0:\n",
    "        \n",
    "        done_gs_df.loc[file_row.Index, \"google_transcription\"] = \"\"\n",
    "\n",
    "        #writes a zero level confidence to the dataframe\n",
    "        done_gs_df.loc[file_row.Index, \"google_ConfidenceLevel\"] = 0\n",
    "\n",
    "    else:\n",
    "\n",
    "        #if the result only has one transcript, writes the transcript to the dataframe\n",
    "        if len(file_response.results) == 1:\n",
    "\n",
    "            # this is coded this way because of the structure of the json\n",
    "            #   res is the json object, which is essentially a python dictionary in this context\n",
    "            #   res['results'] opens the value paired with the key 'results' which is\n",
    "            #   a list of the results. [0] gets the first item which is another dictionary\n",
    "            #   which contains a list of alternatives. since there is only one here, the [0]\n",
    "            #   is used to get the first entry which is a dictionary with a 'transcript' key\n",
    "            #   and the ASR transcribed speech as the value\n",
    "            text = file_response.results[0].alternatives[0].transcript\n",
    "\n",
    "            #writes the text to the dataframe\n",
    "            done_gs_df.loc[file_row.Index, \"google_transcription\"] = text\n",
    "\n",
    "            #creates a variable for the confidence level\n",
    "            # this could be written into the next line, but coding it this way\n",
    "            #  makes the code more readable and understandable for me\n",
    "            confidence_level = file_response.results[0].alternatives[0].confidence\n",
    "\n",
    "            #writes the confidence level to the dataframe\n",
    "            done_gs_df.loc[file_row.Index, \"google_ConfidenceLevel\"] = confidence_level\n",
    "\n",
    "        else:\n",
    "\n",
    "            #if there are multiple alternatives, this code will find the alternative with the\n",
    "            #  highest confidence level and take that as the transcript\n",
    "\n",
    "            #creates an empty list to append tuples to\n",
    "            tuples_list = []\n",
    "\n",
    "            #cycles through the list of results in the res variable\n",
    "            for result in file_response.results:\n",
    "\n",
    "                # for each result, creates a tuple of the confidence level and index of each result in the lisit\n",
    "                confidence_index = (result.alternatives[0].confidence, file_response.results.index(result))\n",
    "\n",
    "                # appends the tuple to the list\n",
    "                tuples_list.append(confidence_index)\n",
    "\n",
    "            #performs the same function as the text= variable in the previous step, except here,\n",
    "            #  the first [0] is replaced with [max(tuples_list)[1]]. What this does is\n",
    "            #  takes the maximum confidence level in the tuples_list by taking the max\n",
    "            #  number in all of the first items in each tuple and then takes the index\n",
    "            #  from the max tuple by accessing its second item, and uses that index\n",
    "            #  as the index for the larger results list\n",
    "            text = file_response.results[max(tuples_list)[1]].alternatives[0].transcript\n",
    "\n",
    "            #writes the text to the dataframe\n",
    "            done_gs_df.loc[file_row.Index, \"google_transcription\"] = text\n",
    "\n",
    "            #creates a variable for the confidence level\n",
    "            # this could be written into the next line, but coding it this way\n",
    "            #  makes the code more readable and understandable for me\n",
    "            confidence_level = file_response.results[max(tuples_list)[1]].alternatives[0].confidence\n",
    "\n",
    "            #writes the confidence level to the dataframe\n",
    "            done_gs_df.loc[file_row.Index, \"google_ConfidenceLevel\"] = confidence_level\n",
    "            \n",
    "#     #enable this if you'd like to print a message that will show the progress\n",
    "#     print(f\"{iteration_number} / {len(done_gs_df)} completed.\")\n",
    "        \n",
    "#     iteration_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38907ad-6f53-498a-b673-f3446370a389",
   "metadata": {},
   "source": [
    "# 4. IBM Watson Speech-to-Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33276f23-5df6-47c3-b884-230f7af69687",
   "metadata": {},
   "source": [
    "This code assumes you have set up an IBM Watson account. For help with start-up, see this link: https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-gettingStarted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f72916-27ca-4be8-86b8-0051c648ced7",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "The following code is adapted directly from [Nicholas Renotte](https://github.com/nicknochnack) (see code [here](https://github.com/nicknochnack/WatsonSTT/blob/master/Watson%20Speech%20to%20Text.ipynb) and video walkthrough [here](https://www.youtube.com/watch?v=A9_0OgW1LZU))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f6e42d-f50b-49fc-b544-aaebdf4f1b31",
   "metadata": {},
   "source": [
    "## 4.1 Initial Set-up\n",
    "\n",
    "To connect to the IBM Watson Speech-to-Text service, you must have an API key and URL. This comes from the IBM account. Follow these steps to get these: \n",
    "1. Go to IBM Cloud console, here: https://cloud.ibm.com/.\n",
    "2. In the hamburger icon (three lines) on the top left, Click 'Resource list'. \n",
    "3. Click 'Services and Software'.\n",
    "4. Click 'Speech to Text-bn'. \n",
    "5. Click 'Manage' (or it may automatically take you to 'Manage').\n",
    "6. You should see 'Credentials'.\n",
    "7. Copy the API Key and URL and insert them in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9975450c-43dc-4188-aba4-059d866f4d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "from ibm_watson import SpeechToTextV1\n",
    "from ibm_watson.websocket import RecognizeCallback, AudioSource \n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3270c77c-83a5-4d70-a2fd-6ca1808e2bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the API Key and URL\n",
    "\n",
    "#this comes from the IBM account. Go to IBM Cloud console >> Resource list >> Services >> \n",
    "#   Speech to Text-bn >> Manage >> Credentials >> Copy the API key and insert it here\n",
    "apikey = \"api-key\"\n",
    "\n",
    "#this comes from the IBM account. Go to IBM Cloud console >> Resource list >> Services >> \n",
    "#   Speech to Text-bn >> Manage >> Credentials >> Copy the URL and insert it here\n",
    "url = \"url\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261bc38f-34e4-425c-b005-f95400086aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Service\n",
    "authenticator = IAMAuthenticator(apikey)\n",
    "\n",
    "stt = SpeechToTextV1(authenticator=authenticator)\n",
    "\n",
    "stt.set_service_url(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08de59ac-408c-4b63-a966-9abb395c8784",
   "metadata": {},
   "source": [
    "## 4.2 Execute the Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da36fbd3-91ef-4975-bd2f-d0425e40c9e4",
   "metadata": {},
   "source": [
    "### Feature: Ain't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad88422-15ab-44e2-b66d-32c3ffc7281b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creates a column for the ibm transcripts\n",
    "aint_gs_df['IBMWatson_transcription'] = np.nan\n",
    "\n",
    "#creates a column for the ibm confidence level\n",
    "aint_gs_df['IBMWatson_ConfidenceLevel'] = np.nan\n",
    "\n",
    "## enable this if you'd like to print a message that will show the progress\n",
    "#iteration_number = 1\n",
    "\n",
    "#cycles through the dataframe rows\n",
    "for file_row in aint_gs_df.itertuples():\n",
    "    \n",
    "    #creates a variable with the filename\n",
    "    # here i've adjusted for my 16khz files. If you don't need this, use the commented out line\n",
    "    filename = f\"16khz_{file_row.File}_Line{file_row.Line}_FeatCount{file_row.FeatureCountPerLine}.wav\"\n",
    "    \n",
    "    #opens the audio file\n",
    "    with open(f'{aint_audio_file_path}{filename}', 'rb') as f:\n",
    "        \n",
    "        #runs the speech recognition and returns a json file with results\n",
    "        #  the results can include either no transcript, one transcript, or alternative transcripts\n",
    "        #  it will also include a confidence level from 0 to 1 \n",
    "        #  this code uses IBM's NarrowBroadband Model which seemed to be the most accurate for the data here\n",
    "        #  other models (at present) include the Broadband model, Multimedia model, and Telephony model\n",
    "        #   see here: https://cloud.ibm.com/apidocs/speech-to-text?code=python#listmodels\n",
    "        res = stt.recognize(audio=f, content_type='audio/wav', model='en-US_NarrowbandModel', continuous=True).get_result()\n",
    "        \n",
    "        #if the service isn't able to produce a transcript, writes a NaN to the dataframe\n",
    "        if len(res['results']) == 0:\n",
    "            \n",
    "            aint_gs_df.loc[file_row.Index, \"IBMWatson_transcription\"] = \"\"\n",
    "            \n",
    "            #writes a zero level confidence to the dataframe\n",
    "            aint_gs_df.loc[file_row.Index, \"IBMWatson_ConfidenceLevel\"] = 0\n",
    "\n",
    "        else:\n",
    "            \n",
    "            #if the result only has one transcript, writes the transcript to the dataframe\n",
    "            if len(res['results']) == 1:\n",
    "                \n",
    "                # this is coded this way because of the structure of the json\n",
    "                #   res is the json object, which is essentially a python dictionary in this context\n",
    "                #   res['results'] opens the value paired with the key 'results' which is\n",
    "                #   a list of the results. [0] gets the first item which is another dictionary\n",
    "                #   which contains a list of alternatives. since there is only one here, the [0]\n",
    "                #   is used to get the first entry which is a dictionary with a 'transcript' key\n",
    "                #   and the ASR transcribed speech as the value\n",
    "                text = res['results'][0]['alternatives'][0]['transcript']\n",
    "                \n",
    "                #writes the text to the dataframe\n",
    "                aint_gs_df.loc[file_row.Index, \"IBMWatson_transcription\"] = text\n",
    "                \n",
    "                #creates a variable for the confidence level\n",
    "                # this could be written into the next line, but coding it this way\n",
    "                #  makes the code more readable and understandable for me\n",
    "                confidence_level = res['results'][0]['alternatives'][0]['confidence']\n",
    "                \n",
    "                #writes the confidence level to the dataframe\n",
    "                aint_gs_df.loc[file_row.Index, \"IBMWatson_ConfidenceLevel\"] = confidence_level\n",
    "\n",
    "            else:\n",
    "                \n",
    "                #if there are multiple alternatives, this code will find the alternative with the\n",
    "                #  highest confidence level and take that as the transcript\n",
    "                \n",
    "                #creates an empty list to append tuples to\n",
    "                tuples_list = []\n",
    "\n",
    "                #cycles through the list of results in the res variable\n",
    "                for result in res['results']:\n",
    "                    \n",
    "                    # for each result, creates a tuple of the confidence level and index of each result in the lisit\n",
    "                    confidence_index = (result['alternatives'][0]['confidence'], res['results'].index(result))\n",
    "                    \n",
    "                    # appends the tuple to the list\n",
    "                    tuples_list.append(confidence_index)\n",
    "                \n",
    "                #performs the same function as the text= variable in the previous step, except here,\n",
    "                #  the first [0] is replaced with [max(tuples_list)[1]]. What this does is\n",
    "                #  takes the maximum confidence level in the tuples_list by taking the max\n",
    "                #  number in all of the first items in each tuple and then takes the index\n",
    "                #  from the max tuple by accessing its second item, and uses that index\n",
    "                #  as the index for the larger results list\n",
    "                text = res['results'][max(tuples_list)[1]]['alternatives'][0]['transcript']\n",
    "\n",
    "                #writes the text to the dataframe\n",
    "                aint_gs_df.loc[file_row.Index, \"IBMWatson_transcription\"] = text\n",
    "                \n",
    "                #creates a variable for the confidence level\n",
    "                # this could be written into the next line, but coding it this way\n",
    "                #  makes the code more readable and understandable for me\n",
    "                confidence_level = res['results'][max(tuples_list)[1]]['alternatives'][0]['confidence']\n",
    "                \n",
    "                #writes the confidence level to the dataframe\n",
    "                aint_gs_df.loc[file_row.Index, \"IBMWatson_ConfidenceLevel\"] = confidence_level\n",
    "                \n",
    "    ##enable this if you'd like to print a message that will show the progress\n",
    "    #print(f\"{iteration_number} / {len(aint_gs_df)} completed.\")\n",
    "        \n",
    "    #iteration_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eeb18c-d278-444b-88ab-31f9bc42d8ac",
   "metadata": {},
   "source": [
    "### Feature: Be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f004930b-aead-4957-816e-e7abe3344cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a column for the ibm transcripts\n",
    "be_gs_df['IBMWatson_transcription'] = np.nan\n",
    "\n",
    "#creates a column for the ibm confidence level\n",
    "be_gs_df['IBMWatson_ConfidenceLevel'] = np.nan\n",
    "\n",
    "## enable this if you'd like to print a message that will show the progress\n",
    "#iteration_number = 1\n",
    "\n",
    "#cycles through the dataframe rows\n",
    "for file_row in be_gs_df.itertuples():\n",
    "    \n",
    "    #creates a variable with the filename\n",
    "    # here i've adjusted for my 16khz files. If you don't need this, use the commented out line\n",
    "    filename = f\"16khz_{file_row.File}_Line{file_row.Line}_FeatCount{file_row.FeatureCountPerLine}.wav\"\n",
    "    \n",
    "    #opens the audio file\n",
    "    with open(f'{be_audio_file_path}{filename}', 'rb') as f:\n",
    "        \n",
    "        #runs the speech recognition and returns a json file with results\n",
    "        #  the results can include either no transcript, one transcript, or alternative transcripts\n",
    "        #  it will also include a confidence level from 0 to 1 \n",
    "        #  this code uses IBM's NarrowBroadband Model which seemed to be the most accurate for the data here\n",
    "        #  other models (at present) include the Broadband model, Multimedia model, and Telephony model\n",
    "        #   see here: https://cloud.ibm.com/apidocs/speech-to-text?code=python#listmodels\n",
    "        res = stt.recognize(audio=f, content_type='audio/wav', model='en-US_NarrowbandModel', continuous=True).get_result()\n",
    "        \n",
    "        #if the service isn't able to produce a transcript, writes a NaN to the dataframe\n",
    "        if len(res['results']) == 0:\n",
    "            \n",
    "            be_gs_df.loc[file_row.Index, \"IBMWatson_transcription\"] = \"\"\n",
    "            \n",
    "            #writes a zero level confidence to the dataframe\n",
    "            be_gs_df.loc[file_row.Index, \"IBMWatson_ConfidenceLevel\"] = 0\n",
    "\n",
    "        else:\n",
    "            \n",
    "            #if the result only has one transcript, writes the transcript to the dataframe\n",
    "            if len(res['results']) == 1:\n",
    "                \n",
    "                # this is coded this way because of the structure of the json\n",
    "                #   res is the json object, which is essentially a python dictionary in this context\n",
    "                #   res['results'] opens the value paired with the key 'results' which is\n",
    "                #   a list of the results. [0] gets the first item which is another dictionary\n",
    "                #   which contains a list of alternatives. since there is only one here, the [0]\n",
    "                #   is used to get the first entry which is a dictionary with a 'transcript' key\n",
    "                #   and the ASR transcribed speech as the value\n",
    "                text = res['results'][0]['alternatives'][0]['transcript']\n",
    "                \n",
    "                #writes the text to the dataframe\n",
    "                be_gs_df.loc[file_row.Index, \"IBMWatson_transcription\"] = text\n",
    "                \n",
    "                #creates a variable for the confidence level\n",
    "                # this could be written into the next line, but coding it this way\n",
    "                #  makes the code more readable and understandable for me\n",
    "                confidence_level = res['results'][0]['alternatives'][0]['confidence']\n",
    "                \n",
    "                #writes the confidence level to the dataframe\n",
    "                be_gs_df.loc[file_row.Index, \"IBMWatson_ConfidenceLevel\"] = confidence_level\n",
    "\n",
    "            else:\n",
    "                \n",
    "                #if there are multiple alternatives, this code will find the alternative with the\n",
    "                #  highest confidence level and take that as the transcript\n",
    "                \n",
    "                #creates an empty list to append tuples to\n",
    "                tuples_list = []\n",
    "\n",
    "                #cycles through the list of results in the res variable\n",
    "                for result in res['results']:\n",
    "                    \n",
    "                    # for each result, creates a tuple of the confidence level and index of each result in the lisit\n",
    "                    confidence_index = (result['alternatives'][0]['confidence'], res['results'].index(result))\n",
    "                    \n",
    "                    # appends the tuple to the list\n",
    "                    tuples_list.append(confidence_index)\n",
    "                \n",
    "                #performs the same function as the text= variable in the previous step, except here,\n",
    "                #  the first [0] is replaced with [max(tuples_list)[1]]. What this does is\n",
    "                #  takes the maximum confidence level in the tuples_list by taking the max\n",
    "                #  number in all of the first items in each tuple and then takes the index\n",
    "                #  from the max tuple by accessing its second item, and uses that index\n",
    "                #  as the index for the larger results list\n",
    "                text = res['results'][max(tuples_list)[1]]['alternatives'][0]['transcript']\n",
    "\n",
    "                #writes the text to the dataframe\n",
    "                be_gs_df.loc[file_row.Index, \"IBMWatson_transcription\"] = text\n",
    "                \n",
    "                #creates a variable for the confidence level\n",
    "                # this could be written into the next line, but coding it this way\n",
    "                #  makes the code more readable and understandable for me\n",
    "                confidence_level = res['results'][max(tuples_list)[1]]['alternatives'][0]['confidence']\n",
    "                \n",
    "                #writes the confidence level to the dataframe\n",
    "                be_gs_df.loc[file_row.Index, \"IBMWatson_ConfidenceLevel\"] = confidence_level\n",
    "                \n",
    "    ##enable this if you'd like to print a message that will show the progress\n",
    "    #print(f\"{iteration_number} / {len(be_gs_df)} completed.\")\n",
    "        \n",
    "    #iteration_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe2dfe2-3fdf-41a4-8042-b64ba163c6a9",
   "metadata": {},
   "source": [
    "### Featue: Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1f6fa7-3d66-4a56-876f-336d8aa7414e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creates a column for the ibm transcripts\n",
    "done_gs_df['IBMWatson_transcription'] = np.nan\n",
    "\n",
    "#creates a column for the ibm confidence level\n",
    "done_gs_df['IBMWatson_ConfidenceLevel'] = np.nan\n",
    "\n",
    "## enable this if you'd like to print a message that will show the progress\n",
    "#iteration_number = 1\n",
    "\n",
    "#cycles through the dataframe rows\n",
    "for file_row in done_gs_df.itertuples():\n",
    "    \n",
    "    #creates a variable with the filename\n",
    "    # here i've adjusted for my 16khz files. If you don't need this, use the commented out line\n",
    "    filename = f\"16khz_{file_row.File}_Line{file_row.Line}_FeatCount{file_row.FeatureCountPerLine}.wav\"\n",
    "    \n",
    "    #opens the audio file\n",
    "    with open(f'{done_audio_file_path}{filename}', 'rb') as f:\n",
    "        \n",
    "        #runs the speech recognition and returns a json file with results\n",
    "        #  the results can include either no transcript, one transcript, or alternative transcripts\n",
    "        #  it will also include a confidence level from 0 to 1 \n",
    "        #  this code uses IBM's NarrowBroadband Model which seemed to be the most accurate for the data here\n",
    "        #  other models (at present) include the Broadband model, Multimedia model, and Telephony model\n",
    "        #   see here: https://cloud.ibm.com/apidocs/speech-to-text?code=python#listmodels\n",
    "        res = stt.recognize(audio=f, content_type='audio/wav', model='en-US_NarrowbandModel', continuous=True).get_result()\n",
    "        \n",
    "        #if the service isn't able to produce a transcript, writes a NaN to the dataframe\n",
    "        if len(res['results']) == 0:\n",
    "            \n",
    "            done_gs_df.loc[file_row.Index, \"IBMWatson_transcription\"] = \"\"\n",
    "            \n",
    "            #writes a zero level confidence to the dataframe\n",
    "            done_gs_df.loc[file_row.Index, \"IBMWatson_ConfidenceLevel\"] = 0\n",
    "\n",
    "        else:\n",
    "            \n",
    "            #if the result only has one transcript, writes the transcript to the dataframe\n",
    "            if len(res['results']) == 1:\n",
    "                \n",
    "                # this is coded this way because of the structure of the json\n",
    "                #   res is the json object, which is essentially a python dictionary in this context\n",
    "                #   res['results'] opens the value paired with the key 'results' which is\n",
    "                #   a list of the results. [0] gets the first item which is another dictionary\n",
    "                #   which contains a list of alternatives. since there is only one here, the [0]\n",
    "                #   is used to get the first entry which is a dictionary with a 'transcript' key\n",
    "                #   and the ASR transcribed speech as the value\n",
    "                text = res['results'][0]['alternatives'][0]['transcript']\n",
    "                \n",
    "                #writes the text to the dataframe\n",
    "                done_gs_df.loc[file_row.Index, \"IBMWatson_transcription\"] = text\n",
    "                \n",
    "                #creates a variable for the confidence level\n",
    "                # this could be written into the next line, but coding it this way\n",
    "                #  makes the code more readable and understandable for me\n",
    "                confidence_level = res['results'][0]['alternatives'][0]['confidence']\n",
    "                \n",
    "                #writes the confidence level to the dataframe\n",
    "                done_gs_df.loc[file_row.Index, \"IBMWatson_ConfidenceLevel\"] = confidence_level\n",
    "\n",
    "            else:\n",
    "                \n",
    "                #if there are multiple alternatives, this code will find the alternative with the\n",
    "                #  highest confidence level and take that as the transcript\n",
    "                \n",
    "                #creates an empty list to append tuples to\n",
    "                tuples_list = []\n",
    "\n",
    "                #cycles through the list of results in the res variable\n",
    "                for result in res['results']:\n",
    "                    \n",
    "                    # for each result, creates a tuple of the confidence level and index of each result in the lisit\n",
    "                    confidence_index = (result['alternatives'][0]['confidence'], res['results'].index(result))\n",
    "                    \n",
    "                    # appends the tuple to the list\n",
    "                    tuples_list.append(confidence_index)\n",
    "                \n",
    "                #performs the same function as the text= variable in the previous step, except here,\n",
    "                #  the first [0] is replaced with [max(tuples_list)[1]]. What this does is\n",
    "                #  takes the maximum confidence level in the tuples_list by taking the max\n",
    "                #  number in all of the first items in each tuple and then takes the index\n",
    "                #  from the max tuple by accessing its second item, and uses that index\n",
    "                #  as the index for the larger results list\n",
    "                text = res['results'][max(tuples_list)[1]]['alternatives'][0]['transcript']\n",
    "\n",
    "                #writes the text to the dataframe\n",
    "                done_gs_df.loc[file_row.Index, \"IBMWatson_transcription\"] = text\n",
    "                \n",
    "                #creates a variable for the confidence level\n",
    "                # this could be written into the next line, but coding it this way\n",
    "                #  makes the code more readable and understandable for me\n",
    "                confidence_level = res['results'][max(tuples_list)[1]]['alternatives'][0]['confidence']\n",
    "                \n",
    "                #writes the confidence level to the dataframe\n",
    "                done_gs_df.loc[file_row.Index, \"IBMWatson_ConfidenceLevel\"] = confidence_level\n",
    "                \n",
    "    ##enable this if you'd like to print a message that will show the progress\n",
    "    #print(f\"{iteration_number} / {len(done_gs_df)} completed.\")\n",
    "        \n",
    "    #iteration_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb6f42f-0b0c-44b8-adc6-041722b09fe6",
   "metadata": {},
   "source": [
    "# 5. Microsoft Azure Cognitive Services Speech-to-Text\n",
    "\n",
    "This code assumes you have set up a Microsoft Azure account. For help with start-up, see this link: https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/get-started-speech-to-text?tabs=windowsinstall&pivots=programming-language-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43ff0c6-92d4-4a23-8409-0a81e557a0f3",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "The code for this is taken directly from Microsoft (see code [here](https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/get-started-speech-to-text))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9a74b5-ccb5-432a-890a-1764560d528b",
   "metadata": {},
   "source": [
    "## 5.1 Initial Set-up\n",
    "\n",
    "To connect to the Microsoft Azure Cognitive Sevices Speech-to-Text service, you must have a speech key and speech location. To get these, follow the steps listed here: https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/overview#find-keys-and-locationregion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea499b7-8b61-4cde-8571-68431eac7298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "import azure.cognitiveservices.speech as speechsdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd91703-6d8c-4149-b14d-65a1fe420b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the speech key and speech location\n",
    "\n",
    "#find these here: https://portal.azure.com/#home >> Click All Resources\n",
    "#  Click the resource you want to use (this should have been created by you) >>\n",
    "#  On the left, click Keys and Endpoint >> Copy either key and the endpoint\n",
    "speech_key = \"speech_key\"\n",
    "\n",
    "speech_location = \"location\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de8662d-1a53-49c2-a994-64f0b760fcb6",
   "metadata": {},
   "source": [
    "## 5.2 Defining the Transcriber Function\n",
    "\n",
    "This code will define a function that runs the transcriber. It will return the transcription and write to the dataframe.\n",
    "\n",
    "This function takes three arguments:\n",
    "1. The speech key\n",
    "2. The speech location\n",
    "3. The audio filename (taken from the dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65edf14a-d8f4-417d-ae32-8bc520b784f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_file(speech_key, speech_location, audio_filename):\n",
    "    \n",
    "    \"\"\"\n",
    "    performs speech to text on audio fil\n",
    "    \"\"\"\n",
    "    \n",
    "    #creates a speech configuration\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_location)\n",
    "    \n",
    "    #gets the audio input\n",
    "    audio_input = speechsdk.AudioConfig(filename=audio_filename)\n",
    "    \n",
    "    #creates a speech recognizer\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_input)\n",
    "    \n",
    "    #runs the speech recognizer\n",
    "    result = speech_recognizer.recognize_once_async().get()\n",
    "    \n",
    "    #returns the result text\n",
    "    return result.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca4f9e8-0c69-4dd4-89a5-73d38c0d1962",
   "metadata": {},
   "source": [
    "## 5.3 Executing the Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b8e709-ec03-45da-8c66-a65cb313b9a0",
   "metadata": {},
   "source": [
    "### Feature: Ain't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc494ea2-8364-45e9-84a7-cda86fea1875",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creates a column for the transcript\n",
    "aint_gs_df['microsoft_transcription'] = np.nan\n",
    "\n",
    "# # enable this if you'd like to print a message that will show the progress\n",
    "# iteration_number = 1\n",
    "\n",
    "#cycles through the dataframe rows\n",
    "for file_row in aint_gs_df.itertuples():\n",
    "    \n",
    "    #creates a variable with the filename\n",
    "    # here i've adjusted for my 16khz files. If you don't need this, use the commented out line\n",
    "    audio_filename = f\"16khz_{file_row.File}_Line{file_row.Line}_FeatCount{file_row.FeatureCountPerLine}.wav\"\n",
    "    \n",
    "    #gets the full audio filepath\n",
    "    audio_path = aint_audio_file_path + audio_filename\n",
    "    \n",
    "    #run the code and get transcription\n",
    "    transcription = from_file(speech_key, speech_location, audio_path)\n",
    "\n",
    "    #writes the transcription to the dataframe\n",
    "    aint_gs_df.loc[file_row.Index, \"microsoft_transcription\"] = transcription\n",
    "    \n",
    "#     #enable this if you'd like to print a message that will show the progress\n",
    "#     print(f\"{iteration_number} / {len(aint_gs_df)} completed.\")\n",
    "        \n",
    "#     iteration_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d4dec7-aaa7-4010-8117-f7c4dab02037",
   "metadata": {},
   "source": [
    "### Feature: Be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28354c7-37a3-4bd1-9758-f557ee5968cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creates a column for the transcript\n",
    "be_gs_df['microsoft_transcription'] = np.nan\n",
    "\n",
    "# enable this if you'd like to print a message that will show the progress\n",
    "iteration_number = 1\n",
    "\n",
    "#cycles through the dataframe rows\n",
    "for file_row in be_gs_df.itertuples():\n",
    "    \n",
    "    #creates a variable with the filename\n",
    "    # here i've adjusted for my 16khz files. If you don't need this, use the commented out line\n",
    "    audio_filename = f\"16khz_{file_row.File}_Line{file_row.Line}_FeatCount{file_row.FeatureCountPerLine}.wav\"\n",
    "    \n",
    "    #gets the full audio filepath\n",
    "    audio_path = be_audio_file_path + audio_filename\n",
    "    \n",
    "    #run the code and get transcription\n",
    "    transcription = from_file(speech_key, speech_location, audio_path)\n",
    "\n",
    "    #writes the transcription to the dataframe\n",
    "    be_gs_df.loc[file_row.Index, \"microsoft_transcription\"] = transcription\n",
    "    \n",
    "    #enable this if you'd like to print a message that will show the progress\n",
    "    print(f\"{iteration_number} / {len(be_gs_df)} completed.\")\n",
    "        \n",
    "    iteration_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ce0026-2484-434e-ac45-1ad4cd9e4cec",
   "metadata": {},
   "source": [
    "### Feature: Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0acfabd-6b1d-472a-9f9c-60d7e8f9a369",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creates a column for the transcript\n",
    "done_gs_df['microsoft_transcription'] = np.nan\n",
    "\n",
    "## enable this if you'd like to print a message that will show the progress\n",
    "#iteration_number = 1\n",
    "\n",
    "#cycles through the dataframe rows\n",
    "for file_row in done_gs_df.itertuples():\n",
    "    \n",
    "    #creates a variable with the filename\n",
    "    # here i've adjusted for my 16khz files. If you don't need this, use the commented out line\n",
    "    audio_filename = f\"16khz_{file_row.File}_Line{file_row.Line}_FeatCount{file_row.FeatureCountPerLine}.wav\"\n",
    "    \n",
    "    #gets the full audio filepath\n",
    "    audio_path = done_audio_file_path + audio_filename\n",
    "    \n",
    "    #run the code and get transcription\n",
    "    transcription = from_file(speech_key, speech_location, audio_path)\n",
    "\n",
    "    #writes the transcription to the dataframe\n",
    "    done_gs_df.loc[file_row.Index, \"microsoft_transcription\"] = transcription\n",
    "    \n",
    "    ##enable this if you'd like to print a message that will show the progress\n",
    "    #print(f\"{iteration_number} / {len(done_gs_df)} completed.\")\n",
    "        \n",
    "    #iteration_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0c303e-b650-4e9d-bc79-e279751611fe",
   "metadata": {},
   "source": [
    "## Sorting the Dataframes by File and Line\n",
    "\n",
    "This will sort the dataframes first by filename and then by line number. Doing this each step will ensure consistency across the board."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef57205-3bfd-4933-bdbe-5f8e6e75ea9d",
   "metadata": {},
   "source": [
    "### Feature: Ain't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f32913-4e1f-44ea-bd82-f0fdbfd167c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aint_gs_df = aint_gs_df.sort_values(by=['File', 'Line'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a08157-c6a8-4cbb-8978-e6af4b931a7e",
   "metadata": {},
   "source": [
    "### Feature: Be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af12356d-7ffb-4af6-9c58-21e00fae9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "be_gs_df = be_gs_df.sort_values(by=['File', 'Line'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39cd837-4bb3-4129-b4db-583aeb11ea90",
   "metadata": {},
   "source": [
    "### Feature: Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cc53ff-73c4-484b-ad31-2025fba38270",
   "metadata": {},
   "outputs": [],
   "source": [
    "done_gs_df = done_gs_df.sort_values(by=['File', 'Line'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f983788-c9a5-4b73-8a2e-1d18a6ae24b9",
   "metadata": {},
   "source": [
    "## Exporting Dataframes to CSV Files\n",
    "\n",
    "This will export the dataframes to CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ff3dee-e5ab-47f3-a75d-14de88610b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate the output path where the CSVs will be stored\n",
    "csv_output_path = \"path\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44331a54-e11e-4b58-813a-717796e37e73",
   "metadata": {},
   "source": [
    "### Feature: Ain't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247e3561-7148-4ace-aa8f-2e2ca60a93e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aint_gs_df.to_csv(f\"{csv_output_path}aint_variations_ASRtranscripts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf982d6-41cb-46d8-9917-8d4a6a5bdd4d",
   "metadata": {},
   "source": [
    "### Feature: Be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b6042b-fa7e-4017-aac3-7cfca0b8fc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "be_gs_df.to_csv(f\"{csv_output_path}be_ASRtranscripts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101802dd-7fd7-4676-a52b-8b9d76e1c990",
   "metadata": {},
   "source": [
    "### Feature: Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4cab56-e32a-467e-aa8e-12a6640b5ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "done_gs_df.to_csv(f\"{csv_output_path}done_ASRtranscripts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec70a6d-72f2-4dc4-b904-b57602cd4e05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
