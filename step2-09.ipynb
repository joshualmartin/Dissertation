{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9af98568-db11-4b00-9546-6cd0c9e4a154",
   "metadata": {},
   "source": [
    "# Step 2.9: Getting Word Error Rates (WER) Pre- and Post-Feature\n",
    "\n",
    "This code will get the Word Error Rate (WER) for the content of ASR output before and after the occurrence of the feature in question by dividing the number of errors by the number of words in the original (cleaned) utterance content which occur either before or after the feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f27e6b-6798-4684-9d4b-b505d5bbc52f",
   "metadata": {},
   "source": [
    "## Required Packages\n",
    "\n",
    "The following packages are necessary to run this code: os, [pandas](https://pypi.org/project/pandas/), [numpy](https://pypi.org/project/numpy/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b082f58c-3a5c-4109-91ae-bf6083dbf0da",
   "metadata": {},
   "source": [
    "## Intitial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9910a3-9f2c-450d-b5e8-70c68efaef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f9bcf7-7295-44d6-8ef7-dabff40708fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath for the csv produced in Step 2.8\n",
    "aint_file_path = \"path\"\n",
    "\n",
    "be_file_path = \"path\"\n",
    "\n",
    "done_file_path = \"path\"\n",
    "\n",
    "#reads in the gold standard dataframe    \n",
    "aint_gs_df = pd.read_csv(aint_file_path)\n",
    "\n",
    "be_gs_df = pd.read_csv(be_file_path)\n",
    "\n",
    "done_gs_df = pd.read_csv(done_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6108b2f4-a3a4-4b60-a39e-2d0ed35a1606",
   "metadata": {},
   "source": [
    "# Defining the Pre-Feature Word Error Rate (WER) Getting Function\n",
    "\n",
    "This function takes the following arguments:\n",
    "1. The number of errors which occur before the feature\n",
    "2. The number of words which occur before the feature (in the cleaned, original utterance content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d874c9-fba0-47a5-8298-44b8c4ea2ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPreFeatureWER(pre_feature_error_count, cleaned_pre_feature_utterance_word_count):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function will get the word error rate (WER) pre-feature\n",
    "    by dividing the number of pre-feature errors by the number\n",
    "    of words in the original (cleaned) utterance content\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        return pre_feature_error_count/cleaned_pre_feature_utterance_word_count\n",
    "    \n",
    "    except ZeroDivisionError:\n",
    "        \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38a0a78-7a99-4e20-9d29-6173d083b245",
   "metadata": {},
   "source": [
    "# Defining the Post-Feature Word Error Rate (WER) Getting Function\n",
    "\n",
    "This function takes the following arguments:\n",
    "1. The number of errors which occur after the feature\n",
    "2. The number of words which occur after the feature (in the cleaned, original utterance content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c85d63a-30e5-462b-897b-7c6315cc1030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPostFeatureWER(post_feature_error_count, cleaned_post_feature_utterance_word_count):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function will get the word error rate (WER) post-feature\n",
    "    by dividing the number of post-feature errors by the number\n",
    "    of words in the original (cleaned) utterance content\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        return post_feature_error_count/cleaned_post_feature_utterance_word_count\n",
    "    \n",
    "    except ZeroDivisionError:\n",
    "        \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc21f853-1ba1-4f40-8a25-51d17bbfe75d",
   "metadata": {},
   "source": [
    "## Executing the Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccd65c1-d80a-4370-b8a0-10a0a1851ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of column names to be appended next to\n",
    "column_names = [\"amazon_transcription_cleaned\", \n",
    "                \"deepspeech_transcription_cleaned\", \"google_transcription_cleaned\", \n",
    "                \"IBMWatson_transcription_cleaned\", \"microsoft_transcription_cleaned\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63203f6b-2d23-492b-a8c3-6bfd15f0125d",
   "metadata": {},
   "source": [
    "### Feature: Ain't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0fe7a4-fbb7-454c-8320-1853dfa98a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appends new columns\n",
    "for column_name in column_names:\n",
    "    \n",
    "    col_index = aint_gs_df.columns.get_loc(column_name)\n",
    "    \n",
    "    aint_gs_df.insert(col_index+5, f\"{column_name}_preFeature_WER\", np.nan)\n",
    "        \n",
    "    aint_gs_df.insert(col_index+7, f\"{column_name}_postFeature_WER\", np.nan)\n",
    "    \n",
    "\n",
    "# loops through rows and executes the fuctions\n",
    "for file_row in aint_gs_df.itertuples():\n",
    "    \n",
    "    aint_gs_df.loc[file_row.Index, \"amazon_transcription_cleaned_preFeature_WER\"] = getPreFeatureWER(file_row.amazon_transcription_cleaned_preFeature_errorCount, file_row.Content_cleaned_PreFeature_WordCount)\n",
    "\n",
    "    aint_gs_df.loc[file_row.Index, \"deepspeech_transcription_cleaned_preFeature_WER\"] = getPreFeatureWER(file_row.deepspeech_transcription_cleaned_preFeature_errorCount, file_row.Content_cleaned_PreFeature_WordCount)\n",
    "\n",
    "    aint_gs_df.loc[file_row.Index, \"google_transcription_cleaned_preFeature_WER\"] = getPreFeatureWER(file_row.google_transcription_cleaned_preFeature_errorCount, file_row.Content_cleaned_PreFeature_WordCount)\n",
    "\n",
    "    aint_gs_df.loc[file_row.Index, \"IBMWatson_transcription_cleaned_preFeature_WER\"] = getPreFeatureWER(file_row.IBMWatson_transcription_cleaned_preFeature_errorCount, file_row.Content_cleaned_PreFeature_WordCount)\n",
    "\n",
    "    aint_gs_df.loc[file_row.Index, \"microsoft_transcription_cleaned_preFeature_WER\"] = getPreFeatureWER(file_row.microsoft_transcription_cleaned_preFeature_errorCount, file_row.Content_cleaned_PreFeature_WordCount)\n",
    "\n",
    "    \n",
    "    \n",
    "    aint_gs_df.loc[file_row.Index, \"amazon_transcription_cleaned_postFeature_WER\"] = getPostFeatureWER(file_row.amazon_transcription_cleaned_postFeature_errorCount, file_row.Content_cleaned_PostFeature_WordCount)\n",
    "\n",
    "    aint_gs_df.loc[file_row.Index, \"deepspeech_transcription_cleaned_postFeature_WER\"] = getPostFeatureWER(file_row.deepspeech_transcription_cleaned_postFeature_errorCount, file_row.Content_cleaned_PostFeature_WordCount)\n",
    "\n",
    "    aint_gs_df.loc[file_row.Index, \"google_transcription_cleaned_postFeature_WER\"] = getPostFeatureWER(file_row.google_transcription_cleaned_postFeature_errorCount, file_row.Content_cleaned_PostFeature_WordCount)\n",
    "\n",
    "    aint_gs_df.loc[file_row.Index, \"IBMWatson_transcription_cleaned_postFeature_WER\"] = getPostFeatureWER(file_row.IBMWatson_transcription_cleaned_postFeature_errorCount, file_row.Content_cleaned_PostFeature_WordCount)\n",
    "\n",
    "    aint_gs_df.loc[file_row.Index, \"microsoft_transcription_cleaned_postFeature_WER\"] = getPostFeatureWER(file_row.microsoft_transcription_cleaned_postFeature_errorCount, file_row.Content_cleaned_PostFeature_WordCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2459f839-307e-4e80-a648-1842e9f01eb5",
   "metadata": {},
   "source": [
    "### Feature: Be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faa61f4-9499-4a75-afcd-b44d3509ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appends new columns\n",
    "for column_name in column_names:\n",
    "    \n",
    "    col_index = be_gs_df.columns.get_loc(column_name)\n",
    "    \n",
    "    be_gs_df.insert(col_index+5, f\"{column_name}_preFeature_WER\", np.nan)\n",
    "        \n",
    "    be_gs_df.insert(col_index+7, f\"{column_name}_postFeature_WER\", np.nan)\n",
    "    \n",
    "\n",
    "# loops through rows and executes the fuctions\n",
    "for file_row in be_gs_df.itertuples():\n",
    "    \n",
    "    be_gs_df.loc[file_row.Index, \"amazon_transcription_cleaned_preFeature_WER\"] = getPreFeatureWER(file_row.amazon_transcription_cleaned_preFeature_errorCount, file_row.Content_cleaned_PreFeature_WordCount)\n",
    "\n",
    "    be_gs_df.loc[file_row.Index, \"deepspeech_transcription_cleaned_preFeature_WER\"] = getPreFeatureWER(file_row.deepspeech_transcription_cleaned_preFeature_errorCount, file_row.Content_cleaned_PreFeature_WordCount)\n",
    "\n",
    "    be_gs_df.loc[file_row.Index, \"google_transcription_cleaned_preFeature_WER\"] = getPreFeatureWER(file_row.google_transcription_cleaned_preFeature_errorCount, file_row.Content_cleaned_PreFeature_WordCount)\n",
    "\n",
    "    be_gs_df.loc[file_row.Index, \"IBMWatson_transcription_cleaned_preFeature_WER\"] = getPreFeatureWER(file_row.IBMWatson_transcription_cleaned_preFeature_errorCount, file_row.Content_cleaned_PreFeature_WordCount)\n",
    "\n",
    "    be_gs_df.loc[file_row.Index, \"microsoft_transcription_cleaned_preFeature_WER\"] = getPreFeatureWER(file_row.microsoft_transcription_cleaned_preFeature_errorCount, file_row.Content_cleaned_PreFeature_WordCount)\n",
    "\n",
    "    \n",
    "    \n",
    "    be_gs_df.loc[file_row.Index, \"amazon_transcription_cleaned_postFeature_WER\"] = getPostFeatureWER(file_row.amazon_transcription_cleaned_postFeature_errorCount, file_row.Content_cleaned_PostFeature_WordCount)\n",
    "\n",
    "    be_gs_df.loc[file_row.Index, \"deepspeech_transcription_cleaned_postFeature_WER\"] = getPostFeatureWER(file_row.deepspeech_transcription_cleaned_postFeature_errorCount, file_row.Content_cleaned_PostFeature_WordCount)\n",
    "\n",
    "    be_gs_df.loc[file_row.Index, \"google_transcription_cleaned_postFeature_WER\"] = getPostFeatureWER(file_row.google_transcription_cleaned_postFeature_errorCount, file_row.Content_cleaned_PostFeature_WordCount)\n",
    "\n",
    "    be_gs_df.loc[file_row.Index, \"IBMWatson_transcription_cleaned_postFeature_WER\"] = getPostFeatureWER(file_row.IBMWatson_transcription_cleaned_postFeature_errorCount, file_row.Content_cleaned_PostFeature_WordCount)\n",
    "\n",
    "    be_gs_df.loc[file_row.Index, \"microsoft_transcription_cleaned_postFeature_WER\"] = getPostFeatureWER(file_row.microsoft_transcription_cleaned_postFeature_errorCount, file_row.Content_cleaned_PostFeature_WordCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1db1093-19ed-4e4b-be56-0aec20f9002c",
   "metadata": {},
   "source": [
    "### Feature: Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb105bf-9f1c-470e-ba6c-9db49b30ec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appends new columns\n",
    "for column_name in column_names:\n",
    "    \n",
    "    col_index = done_gs_df.columns.get_loc(column_name)\n",
    "    \n",
    "    done_gs_df.insert(col_index+5, f\"{column_name}_preFeature_WER\", np.nan)\n",
    "        \n",
    "    done_gs_df.insert(col_index+7, f\"{column_name}_postFeature_WER\", np.nan)\n",
    "    \n",
    "\n",
    "# loops through rows and executes the fuctions\n",
    "for file_row in done_gs_df.itertuples():\n",
    "    \n",
    "    done_gs_df.loc[file_row.Index, \"amazon_transcription_cleaned_preFeature_WER\"] = getPreFeatureWER(file_row.amazon_transcription_cleaned_preFeature_errorCount, file_row.Content_cleaned_PreFeature_WordCount)\n",
    "\n",
    "    done_gs_df.loc[file_row.Index, \"deepspeech_transcription_cleaned_preFeature_WER\"] = getPreFeatureWER(file_row.deepspeech_transcription_cleaned_preFeature_errorCount, file_row.Content_cleaned_PreFeature_WordCount)\n",
    "\n",
    "    done_gs_df.loc[file_row.Index, \"google_transcription_cleaned_preFeature_WER\"] = getPreFeatureWER(file_row.google_transcription_cleaned_preFeature_errorCount, file_row.Content_cleaned_PreFeature_WordCount)\n",
    "\n",
    "    done_gs_df.loc[file_row.Index, \"IBMWatson_transcription_cleaned_preFeature_WER\"] = getPreFeatureWER(file_row.IBMWatson_transcription_cleaned_preFeature_errorCount, file_row.Content_cleaned_PreFeature_WordCount)\n",
    "\n",
    "    done_gs_df.loc[file_row.Index, \"microsoft_transcription_cleaned_preFeature_WER\"] = getPreFeatureWER(file_row.microsoft_transcription_cleaned_preFeature_errorCount, file_row.Content_cleaned_PreFeature_WordCount)\n",
    "\n",
    "    \n",
    "    \n",
    "    done_gs_df.loc[file_row.Index, \"amazon_transcription_cleaned_postFeature_WER\"] = getPostFeatureWER(file_row.amazon_transcription_cleaned_postFeature_errorCount, file_row.Content_cleaned_PostFeature_WordCount)\n",
    "\n",
    "    done_gs_df.loc[file_row.Index, \"deepspeech_transcription_cleaned_postFeature_WER\"] = getPostFeatureWER(file_row.deepspeech_transcription_cleaned_postFeature_errorCount, file_row.Content_cleaned_PostFeature_WordCount)\n",
    "\n",
    "    done_gs_df.loc[file_row.Index, \"google_transcription_cleaned_postFeature_WER\"] = getPostFeatureWER(file_row.google_transcription_cleaned_postFeature_errorCount, file_row.Content_cleaned_PostFeature_WordCount)\n",
    "\n",
    "    done_gs_df.loc[file_row.Index, \"IBMWatson_transcription_cleaned_postFeature_WER\"] = getPostFeatureWER(file_row.IBMWatson_transcription_cleaned_postFeature_errorCount, file_row.Content_cleaned_PostFeature_WordCount)\n",
    "\n",
    "    done_gs_df.loc[file_row.Index, \"microsoft_transcription_cleaned_postFeature_WER\"] = getPostFeatureWER(file_row.microsoft_transcription_cleaned_postFeature_errorCount, file_row.Content_cleaned_PostFeature_WordCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0c303e-b650-4e9d-bc79-e279751611fe",
   "metadata": {},
   "source": [
    "## Sorting the Dataframes by File and Line\n",
    "\n",
    "This will sort the dataframes first by filename and then by line number. Doing this each step will ensure consistency across the board."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef57205-3bfd-4933-bdbe-5f8e6e75ea9d",
   "metadata": {},
   "source": [
    "### Feature: Ain't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f32913-4e1f-44ea-bd82-f0fdbfd167c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aint_gs_df = aint_gs_df.sort_values(by=['File', 'Line'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a08157-c6a8-4cbb-8978-e6af4b931a7e",
   "metadata": {},
   "source": [
    "### Feature: Be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af12356d-7ffb-4af6-9c58-21e00fae9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "be_gs_df = be_gs_df.sort_values(by=['File', 'Line'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39cd837-4bb3-4129-b4db-583aeb11ea90",
   "metadata": {},
   "source": [
    "### Feature: Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cc53ff-73c4-484b-ad31-2025fba38270",
   "metadata": {},
   "outputs": [],
   "source": [
    "done_gs_df = done_gs_df.sort_values(by=['File', 'Line'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f983788-c9a5-4b73-8a2e-1d18a6ae24b9",
   "metadata": {},
   "source": [
    "## Exporting Dataframes to CSV Files\n",
    "\n",
    "This will export the dataframes to CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ff3dee-e5ab-47f3-a75d-14de88610b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate the output path where the CSVs will be stored\n",
    "csv_output_path = \"path\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44331a54-e11e-4b58-813a-717796e37e73",
   "metadata": {},
   "source": [
    "### Feature: Ain't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247e3561-7148-4ace-aa8f-2e2ca60a93e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aint_gs_df.to_csv(f\"{csv_output_path}aint_variations_prePostWER.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf982d6-41cb-46d8-9917-8d4a6a5bdd4d",
   "metadata": {},
   "source": [
    "### Feature: Be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b6042b-fa7e-4017-aac3-7cfca0b8fc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "be_gs_df.to_csv(f\"{csv_output_path}be_prePostWER.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101802dd-7fd7-4676-a52b-8b9d76e1c990",
   "metadata": {},
   "source": [
    "### Feature: Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4cab56-e32a-467e-aa8e-12a6640b5ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "done_gs_df.to_csv(f\"{csv_output_path}done_prePostWER.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3df4499-4d1b-4953-939e-b1179bebf0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
