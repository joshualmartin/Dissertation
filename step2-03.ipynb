{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9af98568-db11-4b00-9546-6cd0c9e4a154",
   "metadata": {},
   "source": [
    "# Step 2.3: Getting Speech Rate\n",
    "\n",
    "This code will give you the speech rate of utterances by getting the number of syllables in a utterances and dividing the utterance length in seconds by the number of syllables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f27e6b-6798-4684-9d4b-b505d5bbc52f",
   "metadata": {},
   "source": [
    "## Required Packages\n",
    "\n",
    "The following packages are necessary to run this code:\n",
    "re, os, string, [pandas](https://pypi.org/project/pandas/), [numpy](https://pypi.org/project/numpy/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54ee4f3-ed83-4359-8a6c-c0a6853d0357",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "The pronunciation dictionary used in this code is adapted from the ARPABET system found here: http://www.speech.cs.cmu.edu/cgi-bin/cmudict. The modified dictionary file used in this code can be found [here](https://www.dropbox.com/s/fz0bxjpsrdghipn/pronunciation_dictionary.txt?dl=0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5221c65d-dbf1-4d96-a712-1fda33232cfd",
   "metadata": {},
   "source": [
    "## Initial Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8757369-62f3-4aa0-81e6-b349b075a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary packages\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d0efc7-5c93-4147-950c-3ecb0d747c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the pronunciation dictionary\n",
    "dictionary_path = \"path\"\n",
    "\n",
    "\n",
    "#this is the path where the CSVs created in Step 2-2 is stored\n",
    "aint_gold_standard_csv_path = \"path\"\n",
    "\n",
    "be_gold_standard_csv_path = \"path\"\n",
    "\n",
    "done_gold_standard_csv_path = \"path\"\n",
    "\n",
    "\n",
    "\n",
    "#This will create the dataframe from the csv\n",
    "aint_gs_df = pd.read_csv(aint_gold_standard_csv_path)\n",
    "\n",
    "be_gs_df = pd.read_csv(be_gold_standard_csv_path)\n",
    "\n",
    "done_gs_df = pd.read_csv(done_gold_standard_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad1ea3d-7d32-4adc-aa3e-5aa71421042a",
   "metadata": {},
   "source": [
    "## Creating the Pronunciation Dictionary\n",
    "\n",
    "This section will take the pronunciation dictionary text file and create a python dictionary out of it. The original dictionary is taken from vowel phonemes from the ARPABET system (which the pronunciation dictionary of the [Montreal Forced Aligner](https://montreal-forced-aligner.readthedocs.io/en/latest/) is based on) which can be found [here](http://www.speech.cs.cmu.edu/cgi-bin/cmudict). The list of vowels is combined with a number which indicates primary, secondary, etc. stress in the word.\n",
    "\n",
    "The modified dictionary file used in this code can be found [here](https://www.dropbox.com/s/fz0bxjpsrdghipn/pronunciation_dictionary.txt?dl=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b6c51b-09d6-47de-9920-272e7217fe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads in the dictionary text file as a list\n",
    "with open(dictionary_path, \"r\") as i:\n",
    "    \n",
    "    dict_lines = i.readlines()\n",
    "\n",
    "    \n",
    "# removes tabs in the list lines\n",
    "dict_lines = [re.sub(r\"\\t\", \" \", x) for x in dict_lines]\n",
    "\n",
    "\n",
    "#creates an empty list to append to\n",
    "new_lines = []\n",
    "\n",
    "\n",
    "# loops through the sorted lines\n",
    "for line in sorted(dict_lines):\n",
    "    \n",
    "    # finds the index of the first space which divides the word and the\n",
    "    # vowels associated with it\n",
    "    space_index = line.find(\" \")\n",
    "    \n",
    "    # makes a line with the @@ symbol to be used as a splitter \n",
    "    line = f\"{line[:space_index]}@@{line[space_index:].strip()}\"\n",
    "    \n",
    "    # appends the new line to the list\n",
    "    new_lines.append(line)\n",
    "\n",
    "    \n",
    "#creates a list of lists for each line\n",
    "dict_lists = [line.split(\"@@\") for line in new_lines]\n",
    "\n",
    "#creates a dictionary from the dict_lists where the \n",
    "#  word is the key and the vowels list is the value\n",
    "#### NOTE: the original dictionary provides\n",
    "####  multiple entries for multiple pronunciations\n",
    "####  the way this code currently works is it will only take the first pronunciation\n",
    "\n",
    "# creates an empty dictionary\n",
    "pronunciationDict = {}\n",
    "\n",
    "\n",
    "# loops through the dict_lists which is a list of lists\n",
    "# composed of 2-item long lists with (1) the word string\n",
    "# and (2) a string of vowels\n",
    "for item in dict_lists:\n",
    "    \n",
    "    # checks the dictionary to see if the word is already present\n",
    "    #  if it is there, then it skips\n",
    "    # this ensures only the first pronunciation will be taken\n",
    "    #  for a word which has multiple entries\n",
    "    if item[0] in pronunciationDict:\n",
    "        \n",
    "        continue\n",
    "    \n",
    "    # creates a key from the word and makes the split vowels list the value\n",
    "    else:\n",
    "        pronunciationDict[item[0]] = item[1].split()\n",
    "\n",
    "        \n",
    "# for some reason, 'be' is messed up in the dictionary. so, this will fix it\n",
    "pronunciationDict['BE'] = ['B', 'EY1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be147ad-9f38-4210-83ca-420020e58a14",
   "metadata": {},
   "source": [
    "## Define the Syllable Counting Function\n",
    "\n",
    "This section will create the function needed to count the syllables in each word. This will be counted by counting the amount of vowels in each word.\n",
    "\n",
    "This function takes the following arguments:\n",
    "\n",
    "<ol>\n",
    "<li>The utterance content as a string</li>\n",
    "<li>The pronunciation dictionary created in the previous step</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f65155-53f1-446b-aefc-4b9897e1552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSyllCount(utterance_content_string, pronunciationDictionary):\n",
    "    \n",
    "    \"\"\"\n",
    "    Gets the syllable count of an utterance\n",
    "    string input must be a string, if it's not, this will return a zero\n",
    "       I put this in here to avoid errors with NaNs in the dataframe\n",
    "    pronunciationDictionary input must be a python dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    # this takes the vowel phonemes from the ARPABET system (which the pronunciation dict of MFA is based on)\n",
    "    # see here: http://www.speech.cs.cmu.edu/cgi-bin/cmudict\n",
    "    # and makes a list of the vowels with the different stresses added\n",
    "    # you can use these to figure out syllable count because syllables are based on vowel. number of vowels = number of syllables\n",
    "    vowels_list = ['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'EH', 'ER', 'EY', 'IH', 'IY', 'OW', 'OY', 'UH', 'UW']\n",
    "    numbers = [0,1,2]\n",
    "\n",
    "    vowelList = [f\"{v}{n}\" for v in vowels_list for n in numbers]\n",
    "\n",
    "    # or just use this\n",
    "\n",
    "    #vowel_phonemes = ['AA0', 'AA1', 'AA2', 'AE0', 'AE1', 'AE2', 'AH0', 'AH1', 'AH2', 'AO0', 'AO1', 'AO2', 'AW0', 'AW1', 'AW2', 'AY0', 'AY1', 'AY2', 'EH0', 'EH1', 'EH2', 'ER0', 'ER1', 'ER2', 'EY0', 'EY1', 'EY2', 'IH0', 'IH1', 'IH2', 'IY0', 'IY1', 'IY2', 'OW0', 'OW1', 'OW2', 'OY0', 'OY1', 'OY2', 'UH0', 'UH1', 'UH2', 'UW0', 'UW1', 'UW2']\n",
    "    # these come from here: http://www.speech.cs.cmu.edu/cgi-bin/cmudict\n",
    "    # the numbers are for stress\n",
    "    \n",
    "    # creates an empty list\n",
    "    total_vowels = []\n",
    "    \n",
    "    # checks the input type. if it is not a string\n",
    "    # then returns a NaN to be appended to the dataframe\n",
    "    if type(utterance_content_string) != str:\n",
    "        \n",
    "        return float(\"NaN\")\n",
    "    \n",
    "    #if the type is a sting, continues\n",
    "    else:\n",
    "        \n",
    "        #creates a list of split words from the utterance content string\n",
    "        string_list = [word.strip(punctuation) for word in utterance_content_string.split()]\n",
    "        \n",
    "        #loops through this new list\n",
    "        for word in string_list:\n",
    "            \n",
    "            #gets the list of phonemes from the word's entry in the pronunciatioin dictionary\n",
    "            phonemes = pronunciationDictionary.get(word.upper()) \n",
    "            \n",
    "            # if there are no phonemes, passes\n",
    "            if phonemes is None:\n",
    "                \n",
    "                pass\n",
    "            \n",
    "            # else, continues\n",
    "            else:\n",
    "                \n",
    "                #loops through the phonemes\n",
    "                for phon in phonemes:\n",
    "                    \n",
    "                    # if the phoneme is in the vowelList, appends the phoneme to the total_vowels list\n",
    "                    if phon in vowelList:\n",
    "                        total_vowels.append(phon)\n",
    "                        \n",
    "                    #if the phonemes is not in the vowels list, passes\n",
    "                    else:\n",
    "                        pass\n",
    "                    \n",
    "        #returns the vowel count in the utterance content line\n",
    "        return(len(total_vowels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476f4536-5510-4632-a102-833c29087d75",
   "metadata": {},
   "source": [
    "## Adding the WADA Speech-to-Noise Ratio Column to the Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a85cd9-f0b0-4843-b049-04e60382bef2",
   "metadata": {},
   "source": [
    "### Feature: Ain't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7912b83-eadc-4769-be3d-368af9328c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a new column for Speech Rate filled with \n",
    "# nan values which will be replaced\n",
    "aint_gs_df[\"SyllableCount\"] = np.nan\n",
    "\n",
    "aint_gs_df[\"SpeechRate\"] = np.nan\n",
    "\n",
    "\n",
    "#loops through the rows of the gold standard dataframe\n",
    "for file_row in aint_gs_df.itertuples():\n",
    "    \n",
    "    # gets the syllable count for the utterance content in the line\n",
    "    content_syllable_count = getSyllCount(file_row.Content, pronunciationDict)\n",
    "    \n",
    "    # if the syllable count is 0, writes a 0\n",
    "    if content_syllable_count == 0:\n",
    "        \n",
    "        aint_gs_df.loc[file_row.Index, \"SyllableCount\"] = 0\n",
    "        \n",
    "        aint_gs_df.loc[file_row.Index, \"SpeechRate\"] = 0\n",
    "    \n",
    "    # else, divides the Utterance length (in seconds) by the syllable count,\n",
    "    #  and writes the result\n",
    "    else:\n",
    "        \n",
    "        aint_gs_df.loc[file_row.Index, \"SyllableCount\"] = float(content_syllable_count)\n",
    "        \n",
    "        aint_gs_df.loc[file_row.Index, \"SpeechRate\"] = float(content_syllable_count/file_row.UttLength)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a8ebad-7d2e-425f-93a2-3f38cd792e27",
   "metadata": {},
   "source": [
    "### Feature: Be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dfe598-92bb-4557-95e7-f0c1d0cdc7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a new column for Speech Rate filled with \n",
    "# nan values which will be replaced\n",
    "be_gs_df[\"SyllableCount\"] = np.nan\n",
    "\n",
    "be_gs_df[\"SpeechRate\"] = np.nan\n",
    "\n",
    "#loops through the rows of the gold standard dataframe\n",
    "for file_row in be_gs_df.itertuples():\n",
    "    \n",
    "    # gets the syllable count for the utterance content in the line\n",
    "    content_syllable_count = getSyllCount(file_row.Content, pronunciationDict)\n",
    "    \n",
    "    # if the syllable count is 0, writes a 0\n",
    "    if content_syllable_count == 0:\n",
    "        \n",
    "        be_gs_df.loc[file_row.Index, \"SyllableCount\"] = 0\n",
    "        \n",
    "        be_gs_df.loc[file_row.Index, \"SpeechRate\"] = 0\n",
    "    \n",
    "    # else, divides the Utterance length (in seconds) by the syllable count,\n",
    "    #  and writes the result\n",
    "    else:\n",
    "        \n",
    "        be_gs_df.loc[file_row.Index, \"SyllableCount\"] = float(content_syllable_count)\n",
    "        \n",
    "        be_gs_df.loc[file_row.Index, \"SpeechRate\"] = float(content_syllable_count/file_row.UttLength)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9b852e-5050-4002-aac5-26a0b1274d94",
   "metadata": {},
   "source": [
    "### Feature: Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5fd207-0a4f-47b1-9c41-ea7621f13aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a new column for Speech Rate filled with \n",
    "# nan values which will be replaced\n",
    "done_gs_df[\"SyllableCount\"] = np.nan\n",
    "\n",
    "done_gs_df[\"SpeechRate\"] = np.nan\n",
    "\n",
    "#loops through the rows of the gold standard dataframe\n",
    "for file_row in done_gs_df.itertuples():\n",
    "    \n",
    "    # gets the syllable count for the utterance content in the line\n",
    "    content_syllable_count = getSyllCount(file_row.Content, pronunciationDict)\n",
    "    \n",
    "    # if the syllable count is 0, writes a 0\n",
    "    if content_syllable_count == 0:\n",
    "        \n",
    "        done_gs_df.loc[file_row.Index, \"SyllableCount\"] = 0\n",
    "        \n",
    "        done_gs_df.loc[file_row.Index, \"SpeechRate\"] = 0\n",
    "    \n",
    "    # else, divides the Utterance length (in seconds) by the syllable count,\n",
    "    #  and writes the result\n",
    "    else:\n",
    "        \n",
    "        done_gs_df.loc[file_row.Index, \"SyllableCount\"] = float(content_syllable_count)\n",
    "        \n",
    "        done_gs_df.loc[file_row.Index, \"SpeechRate\"] = float(content_syllable_count/file_row.UttLength)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0c303e-b650-4e9d-bc79-e279751611fe",
   "metadata": {},
   "source": [
    "## Sorting the Dataframes by File and Line\n",
    "\n",
    "This will sort the dataframes first by filename and then by line number. Doing this each step will ensure consistency across the board."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef57205-3bfd-4933-bdbe-5f8e6e75ea9d",
   "metadata": {},
   "source": [
    "### Feature: Ain't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f32913-4e1f-44ea-bd82-f0fdbfd167c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aint_gs_df = aint_gs_df.sort_values(by=['File', 'Line'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a08157-c6a8-4cbb-8978-e6af4b931a7e",
   "metadata": {},
   "source": [
    "### Feature: Be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af12356d-7ffb-4af6-9c58-21e00fae9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "be_gs_df = be_gs_df.sort_values(by=['File', 'Line'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39cd837-4bb3-4129-b4db-583aeb11ea90",
   "metadata": {},
   "source": [
    "### Feature: Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cc53ff-73c4-484b-ad31-2025fba38270",
   "metadata": {},
   "outputs": [],
   "source": [
    "done_gs_df = done_gs_df.sort_values(by=['File', 'Line'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f983788-c9a5-4b73-8a2e-1d18a6ae24b9",
   "metadata": {},
   "source": [
    "## Exporting Dataframes to CSV Files\n",
    "\n",
    "This will export the dataframes to CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ff3dee-e5ab-47f3-a75d-14de88610b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate the output path where the CSVs will be stored\n",
    "csv_output_path = \"path\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44331a54-e11e-4b58-813a-717796e37e73",
   "metadata": {},
   "source": [
    "### Feature: Ain't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247e3561-7148-4ace-aa8f-2e2ca60a93e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aint_gs_df.to_csv(f\"{csv_output_path}aint_variations_speechRate.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf982d6-41cb-46d8-9917-8d4a6a5bdd4d",
   "metadata": {},
   "source": [
    "### Feature: Be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b6042b-fa7e-4017-aac3-7cfca0b8fc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "be_gs_df.to_csv(f\"{csv_output_path}be_speechRate.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101802dd-7fd7-4676-a52b-8b9d76e1c990",
   "metadata": {},
   "source": [
    "### Feature: Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4cab56-e32a-467e-aa8e-12a6640b5ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "done_gs_df.to_csv(f\"{csv_output_path}done_speechRate.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3df4499-4d1b-4953-939e-b1179bebf0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
